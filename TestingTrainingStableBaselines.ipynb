{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f79043-5ec2-4936-ae0c-62ac99275d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import DQN, PPO\n",
    "from utils import *\n",
    "from data_logger import DataLogger\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b251bf3-67bb-4d42-bfc1-76112dcd55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading parameters\n",
    "ep, lp, hp = get_params() #params[\"environment\"], params[\"logging\"], params[\"hyperparameters\"]\n",
    "hp_algo = hp['dqn/ddqn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d06b0a7-8940-4e22-ab56-74236fbd4bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "#Environment\n",
    "env = get_env(game=ep[\"game\"], level=ep[\"level\"], action_space=ep[\"action_space\"])\n",
    "env = apply_wrappers(env, skip=ep[\"skip\"], gray_scale=ep[\"gray_scale\"], shape=ep[\"frame_shape\"], num_stack=ep[\"num_stack\"])\n",
    "next_state = env.reset()\n",
    "print(next_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8c56af-b648-4827-81e4-6a9655c99292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x1500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import *\n",
    "next_state, reward, done, info = env.step(get_action_sample(env))\n",
    "plot_sequence_observations(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823f10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import collections\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting winrate in tensorboard and saving hyperparameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0, game=\"mario\"):\n",
    "        super().__init__(verbose)\n",
    "        self.reward_history = []\n",
    "        self.win_rate_history = []\n",
    "        self.episodes_prev_act = collections.deque([0, 0], maxlen=2)\n",
    "        self.win_prev_act = collections.deque([0, 0], maxlen=2)\n",
    "        self.game = game\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.episodes_prev_act.append(self.model._episode_num)\n",
    "        if self.game==\"mario\":\n",
    "            self.win_prev_act.append(int(self.locals[\"infos\"][0][\"flag_get\"]))\n",
    "        elif self.game==\"sonic\":\n",
    "            self.win_prev_act.append(int(self.locals[\"dones\"][0] and (self.locals[\"infos\"][0][\"lives\"]==self.locals[\"infos\"][0][\"prev_lives\"])))\n",
    "        \n",
    "        if self.episodes_prev_act[0] != self.episodes_prev_act[1]:\n",
    "            self.logger.record(\"rollout/winrate\", self.win_prev_act[0])\n",
    "            self.win_rate_history.append(self.win_prev_act[0])        \n",
    "            self.reward_history.append(self.model.ep_info_buffer[-1][\"r\"])        \n",
    "        return True   \n",
    "\n",
    "logger = DataLogger(env, hp, model=hp_algo[\"model\"])\n",
    "checkpoint_callback = CheckpointCallback(save_freq=lp[\"n_time_steps_save_model\"], save_path=logger.folder_path_models, name_prefix=\"chkpt\")#saving the model periodically\n",
    "eval_callback = EvalCallback(env, best_model_save_path=logger.folder_path_models, log_path=logger.folder_path_models, eval_freq=lp[\"evaluate_best_model_every\"], deterministic=True, render=False)#evaluating the model periodically and saving the best one\n",
    "log_callback = TensorboardCallback(game = ep[\"game\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9971e1b-6ee3-4022-bb56-757fbc56c2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "#Hyperparams DQN\n",
    "model = DQN(\"CnnPolicy\",\n",
    "            env,\n",
    "            double_dqn = (hp_algo[\"model\"]==\"DDQN\"), \n",
    "            buffer_size = hp_algo[\"buffer_size\"],\n",
    "            batch_size = hp_algo[\"batch_size\"],\n",
    "            learning_starts = hp_algo[\"learning_starts\"],\n",
    "            learning_rate = hp_algo[\"learning_rate\"],\n",
    "            gamma = hp_algo[\"discount_factor\"],  \n",
    "            exploration_fraction = hp_algo[\"exploration_fraction\"],\n",
    "            exploration_final_eps = hp_algo[\"exploration_final_eps\"],\n",
    "            train_freq = hp_algo[\"train_freq\"],                    \n",
    "            target_update_interval = hp_algo[\"target_update_interval\"],   \n",
    "            tensorboard_log = logger.folder_path_train,\n",
    "            verbose = 1,\n",
    "            device = device\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e16ad4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=logger.folder_path_train, learning_rate=hp_algo[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3c72a7-30b7-4ad5-b30d-f9e3b9326a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\SonicTheHedgehog-Genesis\\DDQN\\20240202033654\\train\\train_freq_1_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.87e+03 |\n",
      "|    ep_rew_mean      | 625      |\n",
      "|    exploration_rate | 0.77     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 101      |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 23488    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.637    |\n",
      "|    n_updates        | 22487    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=4255.27 +/- 0.00\n",
      "Episode length: 767.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 767      |\n",
      "|    mean_reward      | 4.26e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.755    |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.878    |\n",
      "|    n_updates        | 23999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.31e+03 |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.584    |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 93       |\n",
      "|    time_elapsed     | 455      |\n",
      "|    total_timesteps  | 42466    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 41465    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=607.08 +/- 0.00\n",
      "Episode length: 106.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 106      |\n",
      "|    mean_reward      | 607      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.51     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 48999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.04e+03 |\n",
      "|    ep_rew_mean      | 1.69e+03 |\n",
      "|    exploration_rate | 0.289    |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 93       |\n",
      "|    time_elapsed     | 777      |\n",
      "|    total_timesteps  | 72500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.67     |\n",
      "|    n_updates        | 71499    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=5129.85 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.13e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.265    |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 73999    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.24e+03 |\n",
      "|    ep_rew_mean      | 2.06e+03 |\n",
      "|    exploration_rate | 0.178    |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 75       |\n",
      "|    time_elapsed     | 1108     |\n",
      "|    total_timesteps  | 83886    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 82885    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=4343.49 +/- 0.00\n",
      "Episode length: 578.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 578      |\n",
      "|    mean_reward      | 4.34e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 98999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.38e+03 |\n",
      "|    ep_rew_mean      | 2.89e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 1387     |\n",
      "|    total_timesteps  | 107583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.99     |\n",
      "|    n_updates        | 106582   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.59e+03 |\n",
      "|    ep_rew_mean      | 3.1e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 77       |\n",
      "|    time_elapsed     | 1416     |\n",
      "|    total_timesteps  | 110186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.24     |\n",
      "|    n_updates        | 109185   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.10e+03 |\n",
      "|    ep_rew_mean      | 3.19e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 1469     |\n",
      "|    total_timesteps  | 114940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.59     |\n",
      "|    n_updates        | 113939   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.66e+03 |\n",
      "|    ep_rew_mean      | 3.12e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 1494     |\n",
      "|    total_timesteps  | 117170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.65     |\n",
      "|    n_updates        | 116169   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=624.16 +/- 0.00\n",
      "Episode length: 96.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 96       |\n",
      "|    mean_reward      | 624      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 125000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 123999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.5e+03  |\n",
      "|    ep_rew_mean      | 3.32e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 78       |\n",
      "|    time_elapsed     | 1598     |\n",
      "|    total_timesteps  | 126125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 125124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.25e+03 |\n",
      "|    ep_rew_mean      | 3.4e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 79       |\n",
      "|    time_elapsed     | 1641     |\n",
      "|    total_timesteps  | 129878   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.54     |\n",
      "|    n_updates        | 128877   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.15e+03 |\n",
      "|    ep_rew_mean      | 3.34e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 79       |\n",
      "|    time_elapsed     | 1740     |\n",
      "|    total_timesteps  | 138734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 137733   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.07e+03 |\n",
      "|    ep_rew_mean      | 3.22e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 80       |\n",
      "|    time_elapsed     | 1836     |\n",
      "|    total_timesteps  | 147377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 146376   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=1678.01 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 1.68e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 150000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.79     |\n",
      "|    n_updates        | 148999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.89e+03 |\n",
      "|    ep_rew_mean      | 3.3e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 2074     |\n",
      "|    total_timesteps  | 150125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 149124   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.7e+03  |\n",
      "|    ep_rew_mean      | 3.24e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 2087     |\n",
      "|    total_timesteps  | 151318   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 150317   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.65e+03 |\n",
      "|    ep_rew_mean      | 3.22e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 73       |\n",
      "|    time_elapsed     | 2172     |\n",
      "|    total_timesteps  | 158857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.13     |\n",
      "|    n_updates        | 157856   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.6e+03  |\n",
      "|    ep_rew_mean      | 3.08e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 73       |\n",
      "|    time_elapsed     | 2259     |\n",
      "|    total_timesteps  | 166662   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.436    |\n",
      "|    n_updates        | 165661   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=3644.39 +/- 0.00\n",
      "Episode length: 396.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 396      |\n",
      "|    mean_reward      | 3.64e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 175000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 173999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.59e+03 |\n",
      "|    ep_rew_mean      | 3.08e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 74       |\n",
      "|    time_elapsed     | 2374     |\n",
      "|    total_timesteps  | 176081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 175080   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.55e+03 |\n",
      "|    ep_rew_mean      | 3e+03    |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 74       |\n",
      "|    time_elapsed     | 2461     |\n",
      "|    total_timesteps  | 183860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 182859   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.53e+03 |\n",
      "|    ep_rew_mean      | 2.99e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 75       |\n",
      "|    time_elapsed     | 2555     |\n",
      "|    total_timesteps  | 192365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 191364   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=1705.52 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 1.71e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 200000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.1      |\n",
      "|    n_updates        | 198999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.53e+03 |\n",
      "|    ep_rew_mean      | 3.02e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 2881     |\n",
      "|    total_timesteps  | 202404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.98     |\n",
      "|    n_updates        | 201403   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.45e+03 |\n",
      "|    ep_rew_mean      | 2.95e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 2919     |\n",
      "|    total_timesteps  | 205762   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.51     |\n",
      "|    n_updates        | 204761   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.42e+03 |\n",
      "|    ep_rew_mean      | 3.01e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 3000     |\n",
      "|    total_timesteps  | 213031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 212030   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.41e+03 |\n",
      "|    ep_rew_mean      | 2.99e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 3092     |\n",
      "|    total_timesteps  | 221391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.07     |\n",
      "|    n_updates        | 220390   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=602.34 +/- 0.00\n",
      "Episode length: 92.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 92       |\n",
      "|    mean_reward      | 602      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 225000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 223999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.36e+03 |\n",
      "|    ep_rew_mean      | 2.98e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 3147     |\n",
      "|    total_timesteps  | 226093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.86     |\n",
      "|    n_updates        | 225092   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.36e+03 |\n",
      "|    ep_rew_mean      | 3e+03    |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 72       |\n",
      "|    time_elapsed     | 3253     |\n",
      "|    total_timesteps  | 235653   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 234652   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 3.11e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 73       |\n",
      "|    time_elapsed     | 3412     |\n",
      "|    total_timesteps  | 249971   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.502    |\n",
      "|    n_updates        | 248970   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=3618.78 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 3.62e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 250000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.89     |\n",
      "|    n_updates        | 248999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 3.15e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 3642     |\n",
      "|    total_timesteps  | 251348   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 250347   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 3.12e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 3690     |\n",
      "|    total_timesteps  | 255658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.76     |\n",
      "|    n_updates        | 254657   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 3.08e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 3794     |\n",
      "|    total_timesteps  | 264885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.459    |\n",
      "|    n_updates        | 263884   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | 2.97e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 3890     |\n",
      "|    total_timesteps  | 273463   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.65     |\n",
      "|    n_updates        | 272462   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=1705.52 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 1.71e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 275000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.925    |\n",
      "|    n_updates        | 273999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | 2.95e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 4142     |\n",
      "|    total_timesteps  | 276730   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.89     |\n",
      "|    n_updates        | 275729   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.64e+03 |\n",
      "|    ep_rew_mean      | 2.89e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 4168     |\n",
      "|    total_timesteps  | 279040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.11     |\n",
      "|    n_updates        | 278039   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.68e+03 |\n",
      "|    ep_rew_mean      | 2.92e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 4233     |\n",
      "|    total_timesteps  | 284849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.71     |\n",
      "|    n_updates        | 283848   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=3734.51 +/- 0.00\n",
      "Episode length: 392.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 392      |\n",
      "|    mean_reward      | 3.73e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 300000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 298999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | 2.93e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 4421     |\n",
      "|    total_timesteps  | 300611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.838    |\n",
      "|    n_updates        | 299610   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 2.91e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 4524     |\n",
      "|    total_timesteps  | 309775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.844    |\n",
      "|    n_updates        | 308774   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | 2.96e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 4570     |\n",
      "|    total_timesteps  | 313936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 312935   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.71e+03 |\n",
      "|    ep_rew_mean      | 3e+03    |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 4622     |\n",
      "|    total_timesteps  | 318531   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.82     |\n",
      "|    n_updates        | 317530   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=3743.99 +/- 0.00\n",
      "Episode length: 466.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 466      |\n",
      "|    mean_reward      | 3.74e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 325000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.853    |\n",
      "|    n_updates        | 323999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 3.05e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 4800     |\n",
      "|    total_timesteps  | 333296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 332295   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | 3.09e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 4895     |\n",
      "|    total_timesteps  | 341895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 340894   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | 3.13e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 4928     |\n",
      "|    total_timesteps  | 344889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 343888   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=5171.59 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.17e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 350000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.818    |\n",
      "|    n_updates        | 348999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | 3.27e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 5210     |\n",
      "|    total_timesteps  | 350853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 349852   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 3.31e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 5227     |\n",
      "|    total_timesteps  | 352317   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 351316   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | 3.36e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 5401     |\n",
      "|    total_timesteps  | 367945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 366944   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=648.82 +/- 0.00\n",
      "Episode length: 73.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 73       |\n",
      "|    mean_reward      | 649      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 375000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.644    |\n",
      "|    n_updates        | 373999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | 3.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 5493     |\n",
      "|    total_timesteps  | 375948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.558    |\n",
      "|    n_updates        | 374947   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | 3.29e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 5498     |\n",
      "|    total_timesteps  | 376445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 375444   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | 3.36e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 5517     |\n",
      "|    total_timesteps  | 378107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.33     |\n",
      "|    n_updates        | 377106   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | 3.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 5610     |\n",
      "|    total_timesteps  | 386424   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 385423   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | 3.36e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 5709     |\n",
      "|    total_timesteps  | 395242   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 394241   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.7e+03  |\n",
      "|    ep_rew_mean      | 3.34e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 5724     |\n",
      "|    total_timesteps  | 396587   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.64     |\n",
      "|    n_updates        | 395586   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | 3.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 5740     |\n",
      "|    total_timesteps  | 397988   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 396987   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=3630.16 +/- 0.00\n",
      "Episode length: 351.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 351      |\n",
      "|    mean_reward      | 3.63e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 400000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 398999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | 3.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 5863     |\n",
      "|    total_timesteps  | 408211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 407210   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | 3.36e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 5952     |\n",
      "|    total_timesteps  | 416140   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 415139   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | 3.42e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 5971     |\n",
      "|    total_timesteps  | 417889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 416888   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | 3.45e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 6022     |\n",
      "|    total_timesteps  | 422402   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 421401   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | 3.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 6032     |\n",
      "|    total_timesteps  | 423354   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.95     |\n",
      "|    n_updates        | 422353   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=5162.10 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.16e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 425000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.826    |\n",
      "|    n_updates        | 423999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.49e+03 |\n",
      "|    ep_rew_mean      | 3.43e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 6270     |\n",
      "|    total_timesteps  | 425421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 424420   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.49e+03 |\n",
      "|    ep_rew_mean      | 3.46e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 6295     |\n",
      "|    total_timesteps  | 427666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 426665   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.51e+03 |\n",
      "|    ep_rew_mean      | 3.48e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 6391     |\n",
      "|    total_timesteps  | 436180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 435179   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.45e+03 |\n",
      "|    ep_rew_mean      | 3.43e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 6497     |\n",
      "|    total_timesteps  | 445739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.64     |\n",
      "|    n_updates        | 444738   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=4223.97 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 4.22e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 450000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 448999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.41e+03 |\n",
      "|    ep_rew_mean      | 3.49e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 6771     |\n",
      "|    total_timesteps  | 450978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 449977   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.47e+03 |\n",
      "|    ep_rew_mean      | 3.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 66       |\n",
      "|    time_elapsed     | 6881     |\n",
      "|    total_timesteps  | 460736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 4.37     |\n",
      "|    n_updates        | 459735   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.44e+03 |\n",
      "|    ep_rew_mean      | 3.55e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 6899     |\n",
      "|    total_timesteps  | 462286   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.1      |\n",
      "|    n_updates        | 461285   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.51e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 6952     |\n",
      "|    total_timesteps  | 466974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 465973   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=4254.32 +/- 0.00\n",
      "Episode length: 379.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 379      |\n",
      "|    mean_reward      | 4.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 475000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.44     |\n",
      "|    n_updates        | 473999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 3.57e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7061     |\n",
      "|    total_timesteps  | 475715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 4.07     |\n",
      "|    n_updates        | 474714   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.43e+03 |\n",
      "|    ep_rew_mean      | 3.64e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7197     |\n",
      "|    total_timesteps  | 487597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.4      |\n",
      "|    n_updates        | 486596   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 3.62e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7213     |\n",
      "|    total_timesteps  | 489011   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.82     |\n",
      "|    n_updates        | 488010   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.38e+03 |\n",
      "|    ep_rew_mean      | 3.58e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7227     |\n",
      "|    total_timesteps  | 490223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 4.04     |\n",
      "|    n_updates        | 489222   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=3645.34 +/- 0.00\n",
      "Episode length: 2117.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.12e+03 |\n",
      "|    mean_reward      | 3.65e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 500000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 498999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.33e+03 |\n",
      "|    ep_rew_mean      | 3.7e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7413     |\n",
      "|    total_timesteps  | 501384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 500383   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.26e+03 |\n",
      "|    ep_rew_mean      | 3.68e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7424     |\n",
      "|    total_timesteps  | 502406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 501405   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 3.87e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 7443     |\n",
      "|    total_timesteps  | 504035   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.86     |\n",
      "|    n_updates        | 503034   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.43e+03 |\n",
      "|    ep_rew_mean      | 3.94e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7637     |\n",
      "|    total_timesteps  | 521068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.956    |\n",
      "|    n_updates        | 520067   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=3733.56 +/- 0.00\n",
      "Episode length: 407.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 407      |\n",
      "|    mean_reward      | 3.73e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 525000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.85     |\n",
      "|    n_updates        | 523999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.4e+03  |\n",
      "|    ep_rew_mean      | 4e+03    |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7712     |\n",
      "|    total_timesteps  | 526723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.439    |\n",
      "|    n_updates        | 525722   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.03e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7744     |\n",
      "|    total_timesteps  | 529545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.758    |\n",
      "|    n_updates        | 528544   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.09e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7760     |\n",
      "|    total_timesteps  | 530923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 529922   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.41e+03 |\n",
      "|    ep_rew_mean      | 4.08e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7853     |\n",
      "|    total_timesteps  | 539123   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.736    |\n",
      "|    n_updates        | 538122   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.4e+03  |\n",
      "|    ep_rew_mean      | 4.12e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7955     |\n",
      "|    total_timesteps  | 548097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.521    |\n",
      "|    n_updates        | 547096   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.34e+03 |\n",
      "|    ep_rew_mean      | 4.2e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 7975     |\n",
      "|    total_timesteps  | 549852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 548851   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=3632.06 +/- 0.00\n",
      "Episode length: 289.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 289      |\n",
      "|    mean_reward      | 3.63e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 550000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.823    |\n",
      "|    n_updates        | 548999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.37e+03 |\n",
      "|    ep_rew_mean      | 4.2e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8043     |\n",
      "|    total_timesteps  | 555093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 554092   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.43e+03 |\n",
      "|    ep_rew_mean      | 4.26e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8157     |\n",
      "|    total_timesteps  | 565103   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 564102   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.43e+03 |\n",
      "|    ep_rew_mean      | 4.3e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8169     |\n",
      "|    total_timesteps  | 566202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 5.32     |\n",
      "|    n_updates        | 565201   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.49e+03 |\n",
      "|    ep_rew_mean      | 4.24e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8263     |\n",
      "|    total_timesteps  | 574481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.86     |\n",
      "|    n_updates        | 573480   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=1032.99 +/- 0.00\n",
      "Episode length: 91.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 91       |\n",
      "|    mean_reward      | 1.03e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 575000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 573999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.48e+03 |\n",
      "|    ep_rew_mean      | 4.26e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8281     |\n",
      "|    total_timesteps  | 575826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 574825   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.4e+03  |\n",
      "|    ep_rew_mean      | 4.22e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8289     |\n",
      "|    total_timesteps  | 576598   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.76     |\n",
      "|    n_updates        | 575597   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.32e+03 |\n",
      "|    ep_rew_mean      | 4.18e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8302     |\n",
      "|    total_timesteps  | 577750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 576749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.28e+03 |\n",
      "|    ep_rew_mean      | 4.15e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 8321     |\n",
      "|    total_timesteps  | 579432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.79     |\n",
      "|    n_updates        | 578431   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.35e+03 |\n",
      "|    ep_rew_mean      | 4.14e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 8500     |\n",
      "|    total_timesteps  | 595387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.02     |\n",
      "|    n_updates        | 594386   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=3646.29 +/- 0.00\n",
      "Episode length: 293.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 293      |\n",
      "|    mean_reward      | 3.65e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 600000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.9      |\n",
      "|    n_updates        | 598999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.46e+03 |\n",
      "|    ep_rew_mean      | 4.17e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 8648     |\n",
      "|    total_timesteps  | 607883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 606882   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.52e+03 |\n",
      "|    ep_rew_mean      | 4.13e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 8772     |\n",
      "|    total_timesteps  | 618930   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.447    |\n",
      "|    n_updates        | 617929   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.44e+03 |\n",
      "|    ep_rew_mean      | 4.08e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 8786     |\n",
      "|    total_timesteps  | 620156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 619155   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=646.92 +/- 0.00\n",
      "Episode length: 85.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 85       |\n",
      "|    mean_reward      | 647      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 625000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 623999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.45e+03 |\n",
      "|    ep_rew_mean      | 3.98e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 8932     |\n",
      "|    total_timesteps  | 633036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.319    |\n",
      "|    n_updates        | 632035   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.53e+03 |\n",
      "|    ep_rew_mean      | 4.01e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 9030     |\n",
      "|    total_timesteps  | 641765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 640764   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=3746.84 +/- 0.00\n",
      "Episode length: 276.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 276      |\n",
      "|    mean_reward      | 3.75e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 650000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.956    |\n",
      "|    n_updates        | 648999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.6e+03  |\n",
      "|    ep_rew_mean      | 4.1e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 9134     |\n",
      "|    total_timesteps  | 650390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.76     |\n",
      "|    n_updates        | 649389   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.5e+03  |\n",
      "|    ep_rew_mean      | 3.92e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 9139     |\n",
      "|    total_timesteps  | 650899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 649898   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.64e+03 |\n",
      "|    ep_rew_mean      | 3.99e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 71       |\n",
      "|    time_elapsed     | 9316     |\n",
      "|    total_timesteps  | 666668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.13     |\n",
      "|    n_updates        | 665667   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 675000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.831    |\n",
      "|    n_updates        | 673999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.71e+03 |\n",
      "|    ep_rew_mean      | 3.94e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 9627     |\n",
      "|    total_timesteps  | 675287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.06     |\n",
      "|    n_updates        | 674286   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | 3.92e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 9722     |\n",
      "|    total_timesteps  | 683751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.545    |\n",
      "|    n_updates        | 682750   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | 3.89e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 9826     |\n",
      "|    total_timesteps  | 693087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.541    |\n",
      "|    n_updates        | 692086   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 700000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.507    |\n",
      "|    n_updates        | 698999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.72e+03 |\n",
      "|    ep_rew_mean      | 3.95e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 10136    |\n",
      "|    total_timesteps  | 701482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 700481   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | 3.98e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 10313    |\n",
      "|    total_timesteps  | 717306   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.41     |\n",
      "|    n_updates        | 716305   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=4244.84 +/- 0.00\n",
      "Episode length: 338.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 338      |\n",
      "|    mean_reward      | 4.24e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 725000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.705    |\n",
      "|    n_updates        | 723999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | 4.09e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 10496    |\n",
      "|    total_timesteps  | 732841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 731840   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | 4.13e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 10598    |\n",
      "|    total_timesteps  | 741949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 740948   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=3638.70 +/- 0.00\n",
      "Episode length: 283.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 283      |\n",
      "|    mean_reward      | 3.64e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 750000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.603    |\n",
      "|    n_updates        | 748999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 4.18e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 10708    |\n",
      "|    total_timesteps  | 750968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 749967   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 4.16e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 10813    |\n",
      "|    total_timesteps  | 760350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 759349   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 4.2e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 10920    |\n",
      "|    total_timesteps  | 769949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 768948   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=9889.56 +/- 0.00\n",
      "Episode length: 497.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 497      |\n",
      "|    mean_reward      | 9.89e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 775000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.03     |\n",
      "|    n_updates        | 773999   |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | 4.29e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 11127    |\n",
      "|    total_timesteps  | 787174   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 786173   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.21e+03 |\n",
      "|    ep_rew_mean      | 4.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 11224    |\n",
      "|    total_timesteps  | 795827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 794826   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 800000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.858    |\n",
      "|    n_updates        | 798999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | 4.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11491    |\n",
      "|    total_timesteps  | 800643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.394    |\n",
      "|    n_updates        | 799642   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 4.47e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11510    |\n",
      "|    total_timesteps  | 802263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.871    |\n",
      "|    n_updates        | 801262   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.27e+03 |\n",
      "|    ep_rew_mean      | 4.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11536    |\n",
      "|    total_timesteps  | 804607   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 803606   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.34e+03 |\n",
      "|    ep_rew_mean      | 4.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11636    |\n",
      "|    total_timesteps  | 813561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.671    |\n",
      "|    n_updates        | 812560   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | 4.43e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11645    |\n",
      "|    total_timesteps  | 814365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.956    |\n",
      "|    n_updates        | 813364   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 4.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11660    |\n",
      "|    total_timesteps  | 815659   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 814658   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 4.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11670    |\n",
      "|    total_timesteps  | 816549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.946    |\n",
      "|    n_updates        | 815548   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 4.42e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 11687    |\n",
      "|    total_timesteps  | 818035   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.697    |\n",
      "|    n_updates        | 817034   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | 4.46e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 11722    |\n",
      "|    total_timesteps  | 821176   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 820175   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=4149.98 +/- 0.00\n",
      "Episode length: 331.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 331      |\n",
      "|    mean_reward      | 4.15e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 825000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.805    |\n",
      "|    n_updates        | 823999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | 4.49e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 11791    |\n",
      "|    total_timesteps  | 826486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.35     |\n",
      "|    n_updates        | 825485   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.78e+03 |\n",
      "|    ep_rew_mean      | 4.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 11810    |\n",
      "|    total_timesteps  | 828230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 827229   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | 4.62e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 11940    |\n",
      "|    total_timesteps  | 839818   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 838817   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 12035    |\n",
      "|    total_timesteps  | 848282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 847281   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=5192.45 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.19e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 850000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 848999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.75e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 12269    |\n",
      "|    total_timesteps  | 850395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 849394   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 12349    |\n",
      "|    total_timesteps  | 857548   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 856547   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 4.62e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 12525    |\n",
      "|    total_timesteps  | 873243   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.651    |\n",
      "|    n_updates        | 872242   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=4148.08 +/- 0.00\n",
      "Episode length: 337.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 337      |\n",
      "|    mean_reward      | 4.15e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 875000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.948    |\n",
      "|    n_updates        | 873999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 4.59e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 12638    |\n",
      "|    total_timesteps  | 882500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 881499   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.74e+03 |\n",
      "|    ep_rew_mean      | 4.57e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 12732    |\n",
      "|    total_timesteps  | 890923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.701    |\n",
      "|    n_updates        | 889922   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.67e+03 |\n",
      "|    ep_rew_mean      | 4.53e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 12828    |\n",
      "|    total_timesteps  | 899433   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.627    |\n",
      "|    n_updates        | 898432   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 900000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 898999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | 4.51e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13216    |\n",
      "|    total_timesteps  | 915363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 914362   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.73e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13310    |\n",
      "|    total_timesteps  | 923759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.425    |\n",
      "|    n_updates        | 922758   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=7723.23 +/- 0.00\n",
      "Episode length: 2372.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 2.37e+03 |\n",
      "|    mean_reward      | 7.72e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 925000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 923999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 4.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13566    |\n",
      "|    total_timesteps  | 940596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 939595   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.79e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13659    |\n",
      "|    total_timesteps  | 948968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 947967   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=4255.27 +/- 0.00\n",
      "Episode length: 365.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 365      |\n",
      "|    mean_reward      | 4.26e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 950000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 948999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.65e+03 |\n",
      "|    ep_rew_mean      | 4.34e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13705    |\n",
      "|    total_timesteps  | 952121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 951120   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | 4.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13722    |\n",
      "|    total_timesteps  | 953709   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 952708   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | 4.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13831    |\n",
      "|    total_timesteps  | 963480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.966    |\n",
      "|    n_updates        | 962479   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.63e+03 |\n",
      "|    ep_rew_mean      | 4.36e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13849    |\n",
      "|    total_timesteps  | 965072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 964071   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | 4.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13863    |\n",
      "|    total_timesteps  | 966326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.35     |\n",
      "|    n_updates        | 965325   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | 4.34e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 13959    |\n",
      "|    total_timesteps  | 974910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.825    |\n",
      "|    n_updates        | 973909   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=975000, episode_reward=5195.30 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 975000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 973999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.62e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 14188    |\n",
      "|    total_timesteps  | 976260   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 975259   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 4.4e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 14281    |\n",
      "|    total_timesteps  | 984561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.684    |\n",
      "|    n_updates        | 983560   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 4.46e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 14297    |\n",
      "|    total_timesteps  | 985996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 984995   |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=4252.42 +/- 0.00\n",
      "Episode length: 416.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 416      |\n",
      "|    mean_reward      | 4.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.876    |\n",
      "|    n_updates        | 998999   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 4.45e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 14553    |\n",
      "|    total_timesteps  | 1007922  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 1006921  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | 4.45e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 14567    |\n",
      "|    total_timesteps  | 1009204  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 1008203  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | 4.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 14583    |\n",
      "|    total_timesteps  | 1010627  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 1009626  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1025000, episode_reward=4340.64 +/- 0.00\n",
      "Episode length: 350.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 350      |\n",
      "|    mean_reward      | 4.34e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1025000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.51     |\n",
      "|    n_updates        | 1023999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 4.4e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 14757    |\n",
      "|    total_timesteps  | 1025313  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.556    |\n",
      "|    n_updates        | 1024312  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 14962    |\n",
      "|    total_timesteps  | 1043719  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.886    |\n",
      "|    n_updates        | 1042718  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=3700.36 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 3.7e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1050000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.524    |\n",
      "|    n_updates        | 1048999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 4.46e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 15335    |\n",
      "|    total_timesteps  | 1057771  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.525    |\n",
      "|    n_updates        | 1056770  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 4.45e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 15349    |\n",
      "|    total_timesteps  | 1059078  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 1058077  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 4.44e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15368    |\n",
      "|    total_timesteps  | 1060787  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 1059786  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1075000, episode_reward=4349.18 +/- 0.00\n",
      "Episode length: 332.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 332      |\n",
      "|    mean_reward      | 4.35e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1075000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.4      |\n",
      "|    n_updates        | 1073999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 4.49e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15564    |\n",
      "|    total_timesteps  | 1077590  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.852    |\n",
      "|    n_updates        | 1076589  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.98e+03 |\n",
      "|    ep_rew_mean      | 4.47e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15591    |\n",
      "|    total_timesteps  | 1080008  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 1079007  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.93e+03 |\n",
      "|    ep_rew_mean      | 4.47e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15639    |\n",
      "|    total_timesteps  | 1084295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.27     |\n",
      "|    n_updates        | 1083294  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 4.45e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15692    |\n",
      "|    total_timesteps  | 1089126  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 1088125  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15785    |\n",
      "|    total_timesteps  | 1097437  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 1096436  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=4248.63 +/- 0.00\n",
      "Episode length: 306.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 306      |\n",
      "|    mean_reward      | 4.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1100000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.5      |\n",
      "|    n_updates        | 1098999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.77e+03 |\n",
      "|    ep_rew_mean      | 4.43e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15832    |\n",
      "|    total_timesteps  | 1100895  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 1099894  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 15926    |\n",
      "|    total_timesteps  | 1109322  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.872    |\n",
      "|    n_updates        | 1108321  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 4.42e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16022    |\n",
      "|    total_timesteps  | 1117970  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.739    |\n",
      "|    n_updates        | 1116969  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1125000, episode_reward=5193.40 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.19e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1125000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.539    |\n",
      "|    n_updates        | 1123999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 4.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16407    |\n",
      "|    total_timesteps  | 1133225  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.519    |\n",
      "|    n_updates        | 1132224  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 4.43e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16431    |\n",
      "|    total_timesteps  | 1135330  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 1134329  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16522    |\n",
      "|    total_timesteps  | 1143536  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.699    |\n",
      "|    n_updates        | 1142535  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 4.34e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16536    |\n",
      "|    total_timesteps  | 1144793  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 1143792  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 4.38e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16554    |\n",
      "|    total_timesteps  | 1146441  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.89     |\n",
      "|    n_updates        | 1145440  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=5331.89 +/- 0.00\n",
      "Episode length: 354.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 354      |\n",
      "|    mean_reward      | 5.33e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1150000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.969    |\n",
      "|    n_updates        | 1148999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 4.42e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16611    |\n",
      "|    total_timesteps  | 1150572  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 1149571  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16627    |\n",
      "|    total_timesteps  | 1152013  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 1151012  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 4.44e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16723    |\n",
      "|    total_timesteps  | 1160680  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.728    |\n",
      "|    n_updates        | 1159679  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1175000, episode_reward=5339.48 +/- 0.00\n",
      "Episode length: 412.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 412      |\n",
      "|    mean_reward      | 5.34e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1175000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 1173999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 4.52e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 16978    |\n",
      "|    total_timesteps  | 1182500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.654    |\n",
      "|    n_updates        | 1181499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 4.51e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17171    |\n",
      "|    total_timesteps  | 1199747  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 1198746  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=3662.42 +/- 0.00\n",
      "Episode length: 286.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 286      |\n",
      "|    mean_reward      | 3.66e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1200000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.517    |\n",
      "|    n_updates        | 1198999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 4.51e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17194    |\n",
      "|    total_timesteps  | 1201161  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 1200160  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 4.52e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17290    |\n",
      "|    total_timesteps  | 1209665  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.879    |\n",
      "|    n_updates        | 1208664  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.86e+03 |\n",
      "|    ep_rew_mean      | 4.49e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17309    |\n",
      "|    total_timesteps  | 1211396  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 1210395  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1225000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1225000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.76     |\n",
      "|    n_updates        | 1223999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 4.48e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17678    |\n",
      "|    total_timesteps  | 1225276  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 1224275  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 4.42e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17692    |\n",
      "|    total_timesteps  | 1226574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 1225573  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | 4.44e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 17886    |\n",
      "|    total_timesteps  | 1243964  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.864    |\n",
      "|    n_updates        | 1242963  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=4986.61 +/- 0.00\n",
      "Episode length: 480.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 480      |\n",
      "|    mean_reward      | 4.99e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1250000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 1248999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 4.5e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 18140    |\n",
      "|    total_timesteps  | 1265636  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 1264635  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.91e+03 |\n",
      "|    ep_rew_mean      | 4.46e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 18168    |\n",
      "|    total_timesteps  | 1268221  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 1267220  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1275000, episode_reward=5064.40 +/- 0.00\n",
      "Episode length: 409.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 409      |\n",
      "|    mean_reward      | 5.06e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1275000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 1273999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 4.48e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 18280    |\n",
      "|    total_timesteps  | 1277077  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.472    |\n",
      "|    n_updates        | 1276076  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | 4.4e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 18294    |\n",
      "|    total_timesteps  | 1278352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.994    |\n",
      "|    n_updates        | 1277351  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.92e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 18327    |\n",
      "|    total_timesteps  | 1281310  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 1280309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.99e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18498    |\n",
      "|    total_timesteps  | 1296634  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 1295633  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 4.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18512    |\n",
      "|    total_timesteps  | 1297908  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 1296907  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.89e+03 |\n",
      "|    ep_rew_mean      | 4.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18522    |\n",
      "|    total_timesteps  | 1298789  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 1297788  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 4.27e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18533    |\n",
      "|    total_timesteps  | 1299707  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.571    |\n",
      "|    n_updates        | 1298706  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=5337.58 +/- 0.00\n",
      "Episode length: 401.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 401      |\n",
      "|    mean_reward      | 5.34e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1300000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.343    |\n",
      "|    n_updates        | 1298999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.82e+03 |\n",
      "|    ep_rew_mean      | 4.2e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18718    |\n",
      "|    total_timesteps  | 1315389  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.921    |\n",
      "|    n_updates        | 1314388  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.84e+03 |\n",
      "|    ep_rew_mean      | 4.24e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18757    |\n",
      "|    total_timesteps  | 1318837  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 1317836  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1325000, episode_reward=5059.65 +/- 0.00\n",
      "Episode length: 428.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 428      |\n",
      "|    mean_reward      | 5.06e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1325000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 1323999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 4.32e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 18850    |\n",
      "|    total_timesteps  | 1326154  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.761    |\n",
      "|    n_updates        | 1325153  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 4.36e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19024    |\n",
      "|    total_timesteps  | 1341833  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.294    |\n",
      "|    n_updates        | 1340832  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=3631.11 +/- 0.00\n",
      "Episode length: 267.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 267      |\n",
      "|    mean_reward      | 3.63e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1350000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.461    |\n",
      "|    n_updates        | 1348999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 4.4e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19130    |\n",
      "|    total_timesteps  | 1350664  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 1349663  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19309    |\n",
      "|    total_timesteps  | 1366810  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.753    |\n",
      "|    n_updates        | 1365809  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1375000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1375000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 1373999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 4.44e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19642    |\n",
      "|    total_timesteps  | 1377886  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 1376885  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 4.43e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19735    |\n",
      "|    total_timesteps  | 1386295  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.613    |\n",
      "|    n_updates        | 1385294  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19786    |\n",
      "|    total_timesteps  | 1390832  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.964    |\n",
      "|    n_updates        | 1389831  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.94e+03 |\n",
      "|    ep_rew_mean      | 4.32e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 19822    |\n",
      "|    total_timesteps  | 1394104  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 1393103  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1400000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 1398999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 4.34e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 20156    |\n",
      "|    total_timesteps  | 1405071  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 1404070  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.04e+03 |\n",
      "|    ep_rew_mean      | 4.27e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 20246    |\n",
      "|    total_timesteps  | 1413184  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.395    |\n",
      "|    n_updates        | 1412183  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.1e+03  |\n",
      "|    ep_rew_mean      | 4.19e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 20336    |\n",
      "|    total_timesteps  | 1421252  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 1420251  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.97e+03 |\n",
      "|    ep_rew_mean      | 4.12e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 20346    |\n",
      "|    total_timesteps  | 1422145  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 1421144  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1425000, episode_reward=3642.50 +/- 0.00\n",
      "Episode length: 244.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 244      |\n",
      "|    mean_reward      | 3.64e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1425000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.62     |\n",
      "|    n_updates        | 1423999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.06e+03 |\n",
      "|    ep_rew_mean      | 4.24e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 20473    |\n",
      "|    total_timesteps  | 1432953  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 1431952  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.05e+03 |\n",
      "|    ep_rew_mean      | 4.25e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 20646    |\n",
      "|    total_timesteps  | 1448574  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 1447573  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=640.28 +/- 0.00\n",
      "Episode length: 74.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 74       |\n",
      "|    mean_reward      | 640      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1450000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 1448999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.85e+03 |\n",
      "|    ep_rew_mean      | 4.14e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 20671    |\n",
      "|    total_timesteps  | 1450585  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 1449584  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 4.12e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 20757    |\n",
      "|    total_timesteps  | 1458359  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.61     |\n",
      "|    n_updates        | 1457358  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.83e+03 |\n",
      "|    ep_rew_mean      | 4.1e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 20774    |\n",
      "|    total_timesteps  | 1459827  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.931    |\n",
      "|    n_updates        | 1458826  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.9e+03  |\n",
      "|    ep_rew_mean      | 4.15e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 70       |\n",
      "|    time_elapsed     | 20865    |\n",
      "|    total_timesteps  | 1468069  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 1467068  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1475000, episode_reward=4948.67 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 4.95e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1475000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 1473999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 4.19e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 21164    |\n",
      "|    total_timesteps  | 1475853  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 1474852  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.81e+03 |\n",
      "|    ep_rew_mean      | 4.22e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 21179    |\n",
      "|    total_timesteps  | 1477168  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 1476167  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 4.25e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 21353    |\n",
      "|    total_timesteps  | 1492914  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.811    |\n",
      "|    n_updates        | 1491913  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=4948.67 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 4.95e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1500000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 1498999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 21896    |\n",
      "|    total_timesteps  | 1522500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 1521499  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1525000, episode_reward=5179.17 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.18e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1525000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.483    |\n",
      "|    n_updates        | 1523999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 4.49e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 22143    |\n",
      "|    total_timesteps  | 1525408  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 1524407  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 22169    |\n",
      "|    total_timesteps  | 1527725  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 1526724  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.65e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 69       |\n",
      "|    time_elapsed     | 22342    |\n",
      "|    total_timesteps  | 1543333  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.544    |\n",
      "|    n_updates        | 1542332  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1550000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 1548999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.66e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 22632    |\n",
      "|    total_timesteps  | 1550296  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.642    |\n",
      "|    n_updates        | 1549295  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | 4.64e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 22726    |\n",
      "|    total_timesteps  | 1558692  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 1557691  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | 4.56e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 22818    |\n",
      "|    total_timesteps  | 1567016  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.448    |\n",
      "|    n_updates        | 1566015  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1575000, episode_reward=4223.97 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 4.22e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1575000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 1573999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 23205    |\n",
      "|    total_timesteps  | 1582813  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 1581812  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | 4.57e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 23325    |\n",
      "|    total_timesteps  | 1593611  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.773    |\n",
      "|    n_updates        | 1592610  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.09e+03 |\n",
      "|    ep_rew_mean      | 4.55e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 23340    |\n",
      "|    total_timesteps  | 1594905  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.435    |\n",
      "|    n_updates        | 1593904  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1600000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.588    |\n",
      "|    n_updates        | 1598999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 23704    |\n",
      "|    total_timesteps  | 1608631  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.03     |\n",
      "|    n_updates        | 1607630  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.65e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 23805    |\n",
      "|    total_timesteps  | 1617678  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 1616677  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 23819    |\n",
      "|    total_timesteps  | 1618894  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 1617893  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1625000, episode_reward=4315.03 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 4.32e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1625000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.666    |\n",
      "|    n_updates        | 1623999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.13e+03 |\n",
      "|    ep_rew_mean      | 4.73e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24111    |\n",
      "|    total_timesteps  | 1626093  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 1625092  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 4.77e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24180    |\n",
      "|    total_timesteps  | 1632237  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 1631236  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.19e+03 |\n",
      "|    ep_rew_mean      | 4.82e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24278    |\n",
      "|    total_timesteps  | 1640991  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 1639990  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.17e+03 |\n",
      "|    ep_rew_mean      | 4.72e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24377    |\n",
      "|    total_timesteps  | 1649927  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 1648926  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=4153.77 +/- 0.00\n",
      "Episode length: 346.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 346      |\n",
      "|    mean_reward      | 4.15e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1650000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.351    |\n",
      "|    n_updates        | 1648999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.11e+03 |\n",
      "|    ep_rew_mean      | 4.68e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24496    |\n",
      "|    total_timesteps  | 1659762  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.526    |\n",
      "|    n_updates        | 1658761  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | 4.73e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24593    |\n",
      "|    total_timesteps  | 1668437  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 1667436  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1675000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1675000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.695    |\n",
      "|    n_updates        | 1673999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.8e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24958    |\n",
      "|    total_timesteps  | 1682500  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.951    |\n",
      "|    n_updates        | 1681499  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.8e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 24972    |\n",
      "|    total_timesteps  | 1683806  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.479    |\n",
      "|    n_updates        | 1682805  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.84e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25067    |\n",
      "|    total_timesteps  | 1692310  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.565    |\n",
      "|    n_updates        | 1691309  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | 4.76e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25080    |\n",
      "|    total_timesteps  | 1693486  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 1692485  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1700000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 1698999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.31e+03 |\n",
      "|    ep_rew_mean      | 4.81e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25461    |\n",
      "|    total_timesteps  | 1708564  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.89     |\n",
      "|    n_updates        | 1707563  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.75e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25553    |\n",
      "|    total_timesteps  | 1716909  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.65     |\n",
      "|    n_updates        | 1715908  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1725000, episode_reward=4341.59 +/- 0.00\n",
      "Episode length: 397.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 397      |\n",
      "|    mean_reward      | 4.34e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1725000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.476    |\n",
      "|    n_updates        | 1723999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.03e+03 |\n",
      "|    ep_rew_mean      | 4.71e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25657    |\n",
      "|    total_timesteps  | 1725280  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 1724279  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.01e+03 |\n",
      "|    ep_rew_mean      | 4.62e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25670    |\n",
      "|    total_timesteps  | 1726384  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 1725383  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.14e+03 |\n",
      "|    ep_rew_mean      | 4.53e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 25846    |\n",
      "|    total_timesteps  | 1742131  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 1741130  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=4258.12 +/- 0.00\n",
      "Episode length: 292.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 292      |\n",
      "|    mean_reward      | 4.26e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1750000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.945    |\n",
      "|    n_updates        | 1748999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | 4.55e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 26029    |\n",
      "|    total_timesteps  | 1757838  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 1756837  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.16e+03 |\n",
      "|    ep_rew_mean      | 4.47e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 26120    |\n",
      "|    total_timesteps  | 1766030  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 1765029  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1775000, episode_reward=5355.61 +/- 0.00\n",
      "Episode length: 387.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 387      |\n",
      "|    mean_reward      | 5.36e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1775000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 1773999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.51e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 26314    |\n",
      "|    total_timesteps  | 1782577  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 3.2      |\n",
      "|    n_updates        | 1781576  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.31e+03 |\n",
      "|    ep_rew_mean      | 4.55e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 26488    |\n",
      "|    total_timesteps  | 1798326  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.787    |\n",
      "|    n_updates        | 1797325  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=4345.38 +/- 0.00\n",
      "Episode length: 374.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 374      |\n",
      "|    mean_reward      | 4.35e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1800000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 1798999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 4.55e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 26614    |\n",
      "|    total_timesteps  | 1808807  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.97     |\n",
      "|    n_updates        | 1807806  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.54e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 26709    |\n",
      "|    total_timesteps  | 1817291  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 1816290  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1825000, episode_reward=5196.25 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.2e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1825000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.497    |\n",
      "|    n_updates        | 1823999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.3e+03  |\n",
      "|    ep_rew_mean      | 4.58e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27011    |\n",
      "|    total_timesteps  | 1825374  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.737    |\n",
      "|    n_updates        | 1824373  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.33e+03 |\n",
      "|    ep_rew_mean      | 4.53e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27187    |\n",
      "|    total_timesteps  | 1841281  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 1840280  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=3641.55 +/- 0.00\n",
      "Episode length: 326.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 326      |\n",
      "|    mean_reward      | 3.64e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1850000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.694    |\n",
      "|    n_updates        | 1848999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.33e+03 |\n",
      "|    ep_rew_mean      | 4.54e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27300    |\n",
      "|    total_timesteps  | 1850664  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 1849663  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.36e+03 |\n",
      "|    ep_rew_mean      | 4.57e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27343    |\n",
      "|    total_timesteps  | 1854511  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.831    |\n",
      "|    n_updates        | 1853510  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.37e+03 |\n",
      "|    ep_rew_mean      | 4.52e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27439    |\n",
      "|    total_timesteps  | 1863170  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.653    |\n",
      "|    n_updates        | 1862169  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.32e+03 |\n",
      "|    ep_rew_mean      | 4.46e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27448    |\n",
      "|    total_timesteps  | 1863994  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 1862993  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.24e+03 |\n",
      "|    ep_rew_mean      | 4.38e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27456    |\n",
      "|    total_timesteps  | 1864760  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 1863759  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1875000, episode_reward=5063.45 +/- 0.00\n",
      "Episode length: 418.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 418      |\n",
      "|    mean_reward      | 5.06e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1875000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.345    |\n",
      "|    n_updates        | 1873999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.26e+03 |\n",
      "|    ep_rew_mean      | 4.42e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 27593    |\n",
      "|    total_timesteps  | 1876034  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 1875033  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.18e+03 |\n",
      "|    ep_rew_mean      | 4.44e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27610    |\n",
      "|    total_timesteps  | 1877566  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 1876565  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.25e+03 |\n",
      "|    ep_rew_mean      | 4.41e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27781    |\n",
      "|    total_timesteps  | 1892983  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.984    |\n",
      "|    n_updates        | 1891982  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 4.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27796    |\n",
      "|    total_timesteps  | 1894352  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 1893351  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.12e+03 |\n",
      "|    ep_rew_mean      | 4.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27812    |\n",
      "|    total_timesteps  | 1895762  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 1894761  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=4252.42 +/- 0.00\n",
      "Episode length: 312.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 312      |\n",
      "|    mean_reward      | 4.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1900000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.715    |\n",
      "|    n_updates        | 1898999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.08e+03 |\n",
      "|    ep_rew_mean      | 4.38e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27873    |\n",
      "|    total_timesteps  | 1900519  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.76     |\n",
      "|    n_updates        | 1899518  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.15e+03 |\n",
      "|    ep_rew_mean      | 4.4e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27966    |\n",
      "|    total_timesteps  | 1908915  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 1907914  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.02e+03 |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27981    |\n",
      "|    total_timesteps  | 1910234  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 1909233  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.95e+03 |\n",
      "|    ep_rew_mean      | 4.39e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 27997    |\n",
      "|    total_timesteps  | 1911742  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 1910741  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.87e+03 |\n",
      "|    ep_rew_mean      | 4.29e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28008    |\n",
      "|    total_timesteps  | 1912672  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 1911671  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.88e+03 |\n",
      "|    ep_rew_mean      | 4.32e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28023    |\n",
      "|    total_timesteps  | 1914027  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 1913026  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.8e+03  |\n",
      "|    ep_rew_mean      | 4.3e+03  |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28118    |\n",
      "|    total_timesteps  | 1922615  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 1921614  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1925000, episode_reward=4251.48 +/- 0.00\n",
      "Episode length: 303.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 303      |\n",
      "|    mean_reward      | 4.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1925000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.748    |\n",
      "|    n_updates        | 1923999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.76e+03 |\n",
      "|    ep_rew_mean      | 4.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28247    |\n",
      "|    total_timesteps  | 1933498  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.622    |\n",
      "|    n_updates        | 1932497  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.69e+03 |\n",
      "|    ep_rew_mean      | 4.35e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28261    |\n",
      "|    total_timesteps  | 1934796  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.751    |\n",
      "|    n_updates        | 1933795  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | 4.33e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28359    |\n",
      "|    total_timesteps  | 1943575  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 1942574  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=5194.35 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 5.19e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1950000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.822    |\n",
      "|    n_updates        | 1948999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.61e+03 |\n",
      "|    ep_rew_mean      | 4.38e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28741    |\n",
      "|    total_timesteps  | 1958934  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.844    |\n",
      "|    n_updates        | 1957933  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.58e+03 |\n",
      "|    ep_rew_mean      | 4.28e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 68       |\n",
      "|    time_elapsed     | 28833    |\n",
      "|    total_timesteps  | 1967254  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.781    |\n",
      "|    n_updates        | 1966253  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1975000, episode_reward=4223.97 +/- 0.00\n",
      "Episode length: 7500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 7.5e+03  |\n",
      "|    mean_reward      | 4.22e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1975000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.574    |\n",
      "|    n_updates        | 1973999  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.59e+03 |\n",
      "|    ep_rew_mean      | 4.29e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 29142    |\n",
      "|    total_timesteps  | 1975800  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.634    |\n",
      "|    n_updates        | 1974799  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.66e+03 |\n",
      "|    ep_rew_mean      | 4.28e+03 |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 1        |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 67       |\n",
      "|    time_elapsed     | 29316    |\n",
      "|    total_timesteps  | 1991508  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 1990507  |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=4253.37 +/- 0.00\n",
      "Episode length: 329.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 329      |\n",
      "|    mean_reward      | 4.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.02     |\n",
      "|    winrate          | 0        |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000000  |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00025  |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 1998999  |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x190d87fdaf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(hp_algo[\"time_steps\"],\n",
    "            callback=[log_callback, checkpoint_callback, eval_callback],\n",
    "            tb_log_name=\"train_freq_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1104e6ca-cc90-4da3-b227-fcbc3c5dd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.total_rewards = log_callback.reward_history\n",
    "logger.wins = log_callback.win_rate_history\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c76838e7-ebac-4f5e-ae36-15f6f90c92e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_average_reward(logger.wins, title=\"Episodes trained vs. Average Rewards\", n_average=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5311455a-b89c-4c8e-a409-56f0bc61399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(r\"logs/SuperMarioBros-1-1-v0/DDQN/20240131041250/train/total_wins\", 'rb') as f:\n",
    "    rews = pickle.load(f)\n",
    "plot_average_reward(rews, title=\"Episodes trained vs. Average Rewards\", n_average=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad067f7d-a469-4fc3-981b-8fe75e0b9b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m obs, _, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(action))\n\u001b[0;32m     16\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Load the trained model\n",
    "model = DQN.load(r\"logs/SonicTheHedgehog-Genesis/DDQN/20240202033654/checkpoints/chkpt_525000_steps.zip\")\n",
    "\n",
    "\n",
    "env = get_env(game=ep[\"game\"], level=ep[\"level\"], action_space=ep[\"action_space\"])\n",
    "env = apply_wrappers(env, skip=ep[\"skip\"], gray_scale=ep[\"gray_scale\"], shape=ep[\"frame_shape\"], num_stack=ep[\"num_stack\"])# Test the model\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(np.array(obs))\n",
    "        #print(action)\n",
    "        obs, _, done, _ = env.step(int(action))\n",
    "        env.render()\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7213c4bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
