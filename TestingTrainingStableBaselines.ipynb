{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f79043-5ec2-4936-ae0c-62ac99275d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import DQN, PPO\n",
    "from utils import *\n",
    "from data_logger import DataLogger\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b251bf3-67bb-4d42-bfc1-76112dcd55be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading parameters\n",
    "ep, lp, hp = get_params(\"mario\") #params[\"environment\"], params[\"logging\"], params[\"hyperparameters\"]\n",
    "hp_algo = hp['ppo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d06b0a7-8940-4e22-ab56-74236fbd4bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "#Environment\n",
    "env = get_env(game=ep[\"game\"], level=ep[\"level\"], action_space=ep[\"action_space\"])\n",
    "env = apply_wrappers(env, skip=ep[\"skip\"], gray_scale=ep[\"gray_scale\"], shape=ep[\"frame_shape\"], num_stack=ep[\"num_stack\"])\n",
    "next_state = env.reset()\n",
    "print(next_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af8c56af-b648-4827-81e4-6a9655c99292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 48, 'y_pos': 121}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2800x1500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import *\n",
    "next_state, reward, done, info = env.step(get_action_sample(env))\n",
    "plot_sequence_observations(next_state)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823f10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import collections\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting winrate in tensorboard and saving hyperparameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0, game=\"mario\"):\n",
    "        super().__init__(verbose)\n",
    "        self.reward_history = []\n",
    "        self.win_rate_history = []\n",
    "        self.episodes_prev_act = collections.deque([0, 0], maxlen=2)\n",
    "        self.win_prev_act = collections.deque([0, 0], maxlen=2)\n",
    "        self.game = game\n",
    "        self.episode_num = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.episodes_prev_act.append(self.episode_num)\n",
    "\n",
    "        if self.game==\"mario\":\n",
    "            if self.locals[\"dones\"][0] or self.locals[\"infos\"][0][\"flag_get\"]:\n",
    "                self.episode_num += 1\n",
    "            self.win_prev_act.append(int(self.locals[\"infos\"][0][\"flag_get\"]))\n",
    "        elif self.game==\"sonic\":\n",
    "            if self.locals[\"dones\"][0]:\n",
    "                self.episode_num += 1\n",
    "            self.win_prev_act.append(int(self.locals[\"dones\"][0] and (self.locals[\"infos\"][0][\"prev_progress\"])))\n",
    "        \n",
    "        if self.episodes_prev_act[0] != self.episodes_prev_act[1]:\n",
    "            self.logger.record(\"rollout/winrate\", self.win_prev_act[0])\n",
    "            self.win_rate_history.append(self.win_prev_act[0])        \n",
    "            self.reward_history.append(self.model.ep_info_buffer[-1][\"r\"])        \n",
    "        return True   \n",
    "\n",
    "logger = DataLogger(env, hp, model=hp_algo[\"model\"])\n",
    "checkpoint_callback = CheckpointCallback(save_freq=lp[\"n_time_steps_save_model\"], save_path=logger.folder_path_models, name_prefix=\"chkpt\")#saving the model periodically\n",
    "eval_callback = EvalCallback(env, best_model_save_path=logger.folder_path_models, log_path=logger.folder_path_models, eval_freq=lp[\"evaluate_best_model_every\"], deterministic=True, render=False)#evaluating the model periodically and saving the best one\n",
    "log_callback = TensorboardCallback(game = ep[\"game\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9971e1b-6ee3-4022-bb56-757fbc56c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparams DQN\n",
    "# model = DQN(\"CnnPolicy\",\n",
    "#             env,\n",
    "#             double_dqn = (hp_algo[\"model\"]==\"DDQN\"), \n",
    "#             buffer_size = hp_algo[\"buffer_size\"],\n",
    "#             batch_size = hp_algo[\"batch_size\"],\n",
    "#             learning_starts = hp_algo[\"learning_starts\"],\n",
    "#             learning_rate = hp_algo[\"learning_rate\"],\n",
    "#             gamma = hp_algo[\"discount_factor\"],  \n",
    "#             exploration_fraction = hp_algo[\"exploration_fraction\"],\n",
    "#             exploration_final_eps = hp_algo[\"exploration_final_eps\"],\n",
    "#             train_freq = hp_algo[\"train_freq\"],                    \n",
    "#             target_update_interval = hp_algo[\"target_update_interval\"],   \n",
    "#             tensorboard_log = logger.folder_path_train,\n",
    "#             verbose = 1,\n",
    "#             device = device\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16ad4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=logger.folder_path_train, learning_rate=hp_algo[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c72a7-30b7-4ad5-b30d-f9e3b9326a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(hp_algo[\"time_steps\"],\n",
    "            callback=[log_callback, checkpoint_callback, eval_callback],\n",
    "            tb_log_name=\"second_training_learning_rate_1e-4\")\n",
    "\n",
    "logger.total_rewards = log_callback.reward_history\n",
    "logger.wins = log_callback.win_rate_history\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad067f7d-a469-4fc3-981b-8fe75e0b9b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m obs, _, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(action))\n\u001b[0;32m     16\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m---> 17\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Load the trained model\n",
    "model = DQN.load(r\"logs/SonicTheHedgehog-Genesis/DDQN/20240202033654/checkpoints/chkpt_525000_steps.zip\")\n",
    "\n",
    "\n",
    "env = get_env(game=ep[\"game\"], level=ep[\"level\"], action_space=ep[\"action_space\"])\n",
    "env = apply_wrappers(env, skip=ep[\"skip\"], gray_scale=ep[\"gray_scale\"], shape=ep[\"frame_shape\"], num_stack=ep[\"num_stack\"])# Test the model\n",
    "\n",
    "while True:\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(np.array(obs))\n",
    "        #print(action)\n",
    "        obs, _, done, _ = env.step(int(action))\n",
    "        env.render()\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7213c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "#Restart training\n",
    "model_path = r\"logs\\SuperMarioBros-1-1-v0\\PPO\\20240205004950\\checkpoints\\chkpt_2000000_steps.zip\"\n",
    "log_path = r\"logs\\SuperMarioBros-1-1-v0\\PPO\\20240205004950\\train\"\n",
    "model = PPO.load(model_path, tensorboard_log=log_path)\n",
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeaecdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\SuperMarioBros-1-1-v0\\PPO\\20240205004950\\train\\PPO_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 212      |\n",
      "|    ep_rew_mean     | 1.71e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 75       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 3236     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 256         |\n",
      "|    ep_rew_mean          | 1.81e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 5284        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011418074 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0993     |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 375         |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 254          |\n",
      "|    ep_rew_mean          | 1.78e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 7332         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064753685 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0998      |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 242          |\n",
      "|    n_updates            | 9780         |\n",
      "|    policy_gradient_loss | -0.000847    |\n",
      "|    value_loss           | 1.01e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 256        |\n",
      "|    ep_rew_mean          | 1.8e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 68         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 9380       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03886694 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 822        |\n",
      "|    n_updates            | 9790       |\n",
      "|    policy_gradient_loss | -0.00151   |\n",
      "|    value_loss           | 1.78e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 312        |\n",
      "|    ep_rew_mean          | 1.81e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 67         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 152        |\n",
      "|    total_timesteps      | 11428      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09726055 |\n",
      "|    clip_fraction        | 0.0751     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0816    |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 61.1       |\n",
      "|    n_updates            | 9800       |\n",
      "|    policy_gradient_loss | 0.0151     |\n",
      "|    value_loss           | 266        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 361         |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 13476       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003986774 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0359     |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 409        |\n",
      "|    ep_rew_mean          | 1.82e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 214        |\n",
      "|    total_timesteps      | 15524      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01933128 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.373     |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 52.8       |\n",
      "|    n_updates            | 9820       |\n",
      "|    policy_gradient_loss | 0.00185    |\n",
      "|    value_loss           | 306        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 450          |\n",
      "|    ep_rew_mean          | 1.84e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 17572        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058629476 |\n",
      "|    clip_fraction        | 0.0739       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 43.5         |\n",
      "|    n_updates            | 9830         |\n",
      "|    policy_gradient_loss | 0.00421      |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 437        |\n",
      "|    ep_rew_mean          | 1.82e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 277        |\n",
      "|    total_timesteps      | 19620      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02193996 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.228     |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 360        |\n",
      "|    n_updates            | 9840       |\n",
      "|    policy_gradient_loss | 0.00427    |\n",
      "|    value_loss           | 1.18e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 474        |\n",
      "|    ep_rew_mean          | 1.83e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 308        |\n",
      "|    total_timesteps      | 21668      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01112812 |\n",
      "|    clip_fraction        | 0.055      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0948    |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 278        |\n",
      "|    n_updates            | 9850       |\n",
      "|    policy_gradient_loss | 0.00149    |\n",
      "|    value_loss           | 723        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 510          |\n",
      "|    ep_rew_mean          | 1.83e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 340          |\n",
      "|    total_timesteps      | 23716        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025163637 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0118      |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 4.61         |\n",
      "|    n_updates            | 9860         |\n",
      "|    policy_gradient_loss | 0.00195      |\n",
      "|    value_loss           | 34.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=1325.00 +/- 0.00\n",
      "Episode length: 149.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 149        |\n",
      "|    mean_reward          | 1.32e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04283315 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.408     |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 4.41       |\n",
      "|    n_updates            | 9870       |\n",
      "|    policy_gradient_loss | 0.00692    |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 474      |\n",
      "|    ep_rew_mean     | 1.76e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 381      |\n",
      "|    total_timesteps | 25764    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 487         |\n",
      "|    ep_rew_mean          | 1.79e+03    |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 27812       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028247064 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0891     |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 2.17e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 513        |\n",
      "|    ep_rew_mean          | 1.79e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 443        |\n",
      "|    total_timesteps      | 29860      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00916298 |\n",
      "|    clip_fraction        | 0.0501     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.107     |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 191        |\n",
      "|    n_updates            | 9890       |\n",
      "|    policy_gradient_loss | 0.00119    |\n",
      "|    value_loss           | 601        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 498         |\n",
      "|    ep_rew_mean          | 1.85e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 31908       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058848366 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.118      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    value_loss           | 49.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | 1.9e+03     |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 505         |\n",
      "|    total_timesteps      | 33956       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011629762 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | 0.00888     |\n",
      "|    value_loss           | 704         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 514         |\n",
      "|    ep_rew_mean          | 1.93e+03    |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 36004       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012317081 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.131      |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 501        |\n",
      "|    ep_rew_mean          | 1.93e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 567        |\n",
      "|    total_timesteps      | 38052      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11003138 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.187     |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 34.8       |\n",
      "|    n_updates            | 9930       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 383        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 489         |\n",
      "|    ep_rew_mean          | 1.97e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 40100       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008298231 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 328         |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 474         |\n",
      "|    ep_rew_mean          | 1.98e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 42148       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011351932 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.000631   |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 445         |\n",
      "|    ep_rew_mean          | 1.94e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 662         |\n",
      "|    total_timesteps      | 44196       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023352776 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 341         |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | 0.00358     |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 457         |\n",
      "|    ep_rew_mean          | 1.97e+03    |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 46244       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042572573 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | 0.00453     |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 465         |\n",
      "|    ep_rew_mean          | 2e+03       |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 48292       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021592477 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.132      |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 80.8        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | 0.00498     |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=1688.00 +/- 0.00\n",
      "Episode length: 202.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 202         |\n",
      "|    mean_reward          | 1.69e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012886063 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 503         |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | 0.00931     |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 455      |\n",
      "|    ep_rew_mean     | 1.96e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 767      |\n",
      "|    total_timesteps | 50340    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 455         |\n",
      "|    ep_rew_mean          | 1.96e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 798         |\n",
      "|    total_timesteps      | 52388       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010849099 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 992         |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | 0.0059      |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 402         |\n",
      "|    ep_rew_mean          | 1.94e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 830         |\n",
      "|    total_timesteps      | 54436       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020051438 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 2.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 394         |\n",
      "|    ep_rew_mean          | 1.93e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 861         |\n",
      "|    total_timesteps      | 56484       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044698782 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.14       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | 0.00209     |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 383          |\n",
      "|    ep_rew_mean          | 1.96e+03     |\n",
      "|    winrate              | 1            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 892          |\n",
      "|    total_timesteps      | 58532        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049266806 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.023       |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 442          |\n",
      "|    n_updates            | 10030        |\n",
      "|    policy_gradient_loss | 0.00574      |\n",
      "|    value_loss           | 434          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 357        |\n",
      "|    ep_rew_mean          | 2.01e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 924        |\n",
      "|    total_timesteps      | 60580      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01982863 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.149     |\n",
      "|    explained_variance   | 0.857      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 975        |\n",
      "|    n_updates            | 10040      |\n",
      "|    policy_gradient_loss | 0.0037     |\n",
      "|    value_loss           | 1.53e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 363         |\n",
      "|    ep_rew_mean          | 2.04e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 956         |\n",
      "|    total_timesteps      | 62628       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021650005 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.137      |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | 0.00554     |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 2.05e+03    |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 64676       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023637434 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | 0.00794     |\n",
      "|    value_loss           | 1.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 66724       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027846908 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.162      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 925         |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | 0.00818     |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 325         |\n",
      "|    ep_rew_mean          | 2.02e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1050        |\n",
      "|    total_timesteps      | 68772       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044826426 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.177      |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | 0.00275     |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "|    winrate              | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 70820       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032148536 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.141      |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | 1.97e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1113        |\n",
      "|    total_timesteps      | 72868       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060444154 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.213      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | 1.97e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1146        |\n",
      "|    total_timesteps      | 74916       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025470736 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.158      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 937         |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    value_loss           | 5.11e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=820.00 +/- 0.00\n",
      "Episode length: 115.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 115         |\n",
      "|    mean_reward          | 820         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011253576 |\n",
      "|    clip_fraction        | 0.0299      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0394     |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | 0.00454     |\n",
      "|    value_loss           | 382         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | 1.95e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 1184     |\n",
      "|    total_timesteps | 76964    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 352        |\n",
      "|    ep_rew_mean          | 1.98e+03   |\n",
      "|    winrate              | 1          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1215       |\n",
      "|    total_timesteps      | 79012      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13081214 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.229     |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 177        |\n",
      "|    n_updates            | 10130      |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 2.21e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 366         |\n",
      "|    ep_rew_mean          | 2.04e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1247        |\n",
      "|    total_timesteps      | 81060       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036427632 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.182      |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 492         |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | 0.0083      |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 361        |\n",
      "|    ep_rew_mean          | 2.06e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 1278       |\n",
      "|    total_timesteps      | 83108      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02834873 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.181     |\n",
      "|    explained_variance   | 0.908      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 231        |\n",
      "|    n_updates            | 10150      |\n",
      "|    policy_gradient_loss | 0.00308    |\n",
      "|    value_loss           | 1.24e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1310        |\n",
      "|    total_timesteps      | 85156       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014816372 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.147      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.08e+03    |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 365         |\n",
      "|    ep_rew_mean          | 2.08e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1341        |\n",
      "|    total_timesteps      | 87204       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022680145 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.187      |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 478         |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | 0.00702     |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 367        |\n",
      "|    ep_rew_mean          | 2.12e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 1373       |\n",
      "|    total_timesteps      | 89252      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07157321 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.34e+03   |\n",
      "|    n_updates            | 10180      |\n",
      "|    policy_gradient_loss | 0.0323     |\n",
      "|    value_loss           | 2.6e+03    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 368       |\n",
      "|    ep_rew_mean          | 2.12e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 64        |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 1404      |\n",
      "|    total_timesteps      | 91300     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0940648 |\n",
      "|    clip_fraction        | 0.1       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0911   |\n",
      "|    explained_variance   | 0.848     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 1.02e+03  |\n",
      "|    n_updates            | 10190     |\n",
      "|    policy_gradient_loss | 0.00958   |\n",
      "|    value_loss           | 2.34e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | 2.13e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1435        |\n",
      "|    total_timesteps      | 93348       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055904455 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0696     |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.000551   |\n",
      "|    value_loss           | 643         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 382         |\n",
      "|    ep_rew_mean          | 2.13e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1466        |\n",
      "|    total_timesteps      | 95396       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015147486 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0271     |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | 0.00483     |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 2.13e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1498        |\n",
      "|    total_timesteps      | 97444       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016063452 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0682     |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 341         |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | 0.00403     |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 411          |\n",
      "|    ep_rew_mean          | 2.1e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1528         |\n",
      "|    total_timesteps      | 99492        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040473123 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0321      |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 10230        |\n",
      "|    policy_gradient_loss | 0.00358      |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=1909.00 +/- 0.00\n",
      "Episode length: 235.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 235         |\n",
      "|    mean_reward          | 1.91e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009704845 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.132      |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 407      |\n",
      "|    ep_rew_mean     | 2.07e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1573     |\n",
      "|    total_timesteps | 101540   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | 2.06e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1604        |\n",
      "|    total_timesteps      | 103588      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005554083 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.076      |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.06e+03    |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | 0.00355     |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 440        |\n",
      "|    ep_rew_mean          | 2.06e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 1634       |\n",
      "|    total_timesteps      | 105636     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09296639 |\n",
      "|    clip_fraction        | 0.0239     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0448    |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 10260      |\n",
      "|    policy_gradient_loss | 0.00441    |\n",
      "|    value_loss           | 112        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 459         |\n",
      "|    ep_rew_mean          | 2.07e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 1665        |\n",
      "|    total_timesteps      | 107684      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005527945 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0602     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | 0.000913    |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 473        |\n",
      "|    ep_rew_mean          | 2.05e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 1696       |\n",
      "|    total_timesteps      | 109732     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14289516 |\n",
      "|    clip_fraction        | 0.0105     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0157    |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 6.83       |\n",
      "|    n_updates            | 10280      |\n",
      "|    policy_gradient_loss | 0.00288    |\n",
      "|    value_loss           | 60.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 490          |\n",
      "|    ep_rew_mean          | 2.05e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 1727         |\n",
      "|    total_timesteps      | 111780       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011996474 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0358      |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 8.63         |\n",
      "|    n_updates            | 10290        |\n",
      "|    policy_gradient_loss | -0.000499    |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 498          |\n",
      "|    ep_rew_mean          | 2e+03        |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 1758         |\n",
      "|    total_timesteps      | 113828       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075277938 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.041       |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 24.9         |\n",
      "|    n_updates            | 10300        |\n",
      "|    policy_gradient_loss | -0.000546    |\n",
      "|    value_loss           | 37.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 513         |\n",
      "|    ep_rew_mean          | 1.99e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1789        |\n",
      "|    total_timesteps      | 115876      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007241629 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0398     |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 611         |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 527        |\n",
      "|    ep_rew_mean          | 1.98e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 1821       |\n",
      "|    total_timesteps      | 117924     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04026607 |\n",
      "|    clip_fraction        | 0.015      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0494    |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 17.2       |\n",
      "|    n_updates            | 10320      |\n",
      "|    policy_gradient_loss | -0.001     |\n",
      "|    value_loss           | 132        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 522         |\n",
      "|    ep_rew_mean          | 1.96e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1852        |\n",
      "|    total_timesteps      | 119972      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008397572 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0419     |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 512         |\n",
      "|    ep_rew_mean          | 1.81e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1883        |\n",
      "|    total_timesteps      | 122020      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009184766 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0158     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 55.6        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.000815   |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 1.67e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 1914       |\n",
      "|    total_timesteps      | 124068     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15670168 |\n",
      "|    clip_fraction        | 0.0435     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0382    |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 2.85e+03   |\n",
      "|    n_updates            | 10350      |\n",
      "|    policy_gradient_loss | 0.00405    |\n",
      "|    value_loss           | 6.85e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=252.00 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 252         |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 125000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030173369 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0569     |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 524      |\n",
      "|    ep_rew_mean     | 1.68e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 61       |\n",
      "|    time_elapsed    | 1948     |\n",
      "|    total_timesteps | 126116   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 547       |\n",
      "|    ep_rew_mean          | 1.68e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 64        |\n",
      "|    iterations           | 62        |\n",
      "|    time_elapsed         | 1980      |\n",
      "|    total_timesteps      | 128164    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.9426308 |\n",
      "|    clip_fraction        | 0.393     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0228   |\n",
      "|    explained_variance   | 0.901     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 46.3      |\n",
      "|    n_updates            | 10370     |\n",
      "|    policy_gradient_loss | -0.042    |\n",
      "|    value_loss           | 638       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 533        |\n",
      "|    ep_rew_mean          | 1.66e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 2013       |\n",
      "|    total_timesteps      | 130212     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16950761 |\n",
      "|    clip_fraction        | 0.45       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.377     |\n",
      "|    explained_variance   | 0.436      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 152        |\n",
      "|    n_updates            | 10380      |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 646        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 472         |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2045        |\n",
      "|    total_timesteps      | 132260      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051968597 |\n",
      "|    clip_fraction        | 0.0298      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0399     |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | 0.00693     |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 2077        |\n",
      "|    total_timesteps      | 134308      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052162357 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.06       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.89e+03    |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | 0.00531     |\n",
      "|    value_loss           | 4.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 503         |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 2109        |\n",
      "|    total_timesteps      | 136356      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027961306 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0678     |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.0324     |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 522         |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 2142        |\n",
      "|    total_timesteps      | 138404      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016282566 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0355     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 6.46        |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 69.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 539        |\n",
      "|    ep_rew_mean          | 1.22e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 2175       |\n",
      "|    total_timesteps      | 140452     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45927188 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.202     |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 10430      |\n",
      "|    policy_gradient_loss | -0.00555   |\n",
      "|    value_loss           | 36.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 2207        |\n",
      "|    total_timesteps      | 142500      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015311813 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0323     |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.00031    |\n",
      "|    value_loss           | 93.9        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 574           |\n",
      "|    ep_rew_mean          | 1.18e+03      |\n",
      "|    winrate              | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 64            |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 2238          |\n",
      "|    total_timesteps      | 144548        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023378755 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00225      |\n",
      "|    explained_variance   | 0.96          |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 11.5          |\n",
      "|    n_updates            | 10450         |\n",
      "|    policy_gradient_loss | -0.00011      |\n",
      "|    value_loss           | 215           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 592           |\n",
      "|    ep_rew_mean          | 1.17e+03      |\n",
      "|    winrate              | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 64            |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 2271          |\n",
      "|    total_timesteps      | 146596        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075191725 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00248      |\n",
      "|    explained_variance   | 0.674         |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 37.7          |\n",
      "|    n_updates            | 10460         |\n",
      "|    policy_gradient_loss | -0.000385     |\n",
      "|    value_loss           | 573           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 611          |\n",
      "|    ep_rew_mean          | 1.16e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 2304         |\n",
      "|    total_timesteps      | 148644       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004370748 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00233     |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 10470        |\n",
      "|    policy_gradient_loss | -0.00028     |\n",
      "|    value_loss           | 421          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.00e+03     |\n",
      "|    mean_reward          | -21          |\n",
      "| rollout/                |              |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010553205 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00244     |\n",
      "|    explained_variance   | 0.81         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 59.1         |\n",
      "|    n_updates            | 10480        |\n",
      "|    policy_gradient_loss | -0.000844    |\n",
      "|    value_loss           | 273          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 627      |\n",
      "|    ep_rew_mean     | 1.13e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 73       |\n",
      "|    time_elapsed    | 2454     |\n",
      "|    total_timesteps | 150692   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 653        |\n",
      "|    ep_rew_mean          | 1.12e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 2487       |\n",
      "|    total_timesteps      | 152740     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00442597 |\n",
      "|    clip_fraction        | 0.00474    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00287   |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 211        |\n",
      "|    n_updates            | 10490      |\n",
      "|    policy_gradient_loss | -0.000642  |\n",
      "|    value_loss           | 629        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | 1.05e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 2519        |\n",
      "|    total_timesteps      | 154788      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002483346 |\n",
      "|    clip_fraction        | 0.00132     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00156    |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 7.11        |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.000744   |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 678         |\n",
      "|    ep_rew_mean          | 1.01e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 2552        |\n",
      "|    total_timesteps      | 156836      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003345887 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.006      |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 695          |\n",
      "|    ep_rew_mean          | 990          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 2584         |\n",
      "|    total_timesteps      | 158884       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128817875 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0105      |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 54.3         |\n",
      "|    n_updates            | 10520        |\n",
      "|    policy_gradient_loss | 0.00513      |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 971         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2616        |\n",
      "|    total_timesteps      | 160932      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004753728 |\n",
      "|    clip_fraction        | 0.0064      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00807    |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 729          |\n",
      "|    ep_rew_mean          | 949          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 2649         |\n",
      "|    total_timesteps      | 162980       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032417485 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0104      |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 10540        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    value_loss           | 35.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 731          |\n",
      "|    ep_rew_mean          | 920          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 2681         |\n",
      "|    total_timesteps      | 165028       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044444134 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0175      |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 10550        |\n",
      "|    policy_gradient_loss | -0.000311    |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 716       |\n",
      "|    ep_rew_mean          | 911       |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 61        |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 2714      |\n",
      "|    total_timesteps      | 167076    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1115845 |\n",
      "|    clip_fraction        | 0.158     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.915     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 221       |\n",
      "|    n_updates            | 10560     |\n",
      "|    policy_gradient_loss | -0.0141   |\n",
      "|    value_loss           | 236       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 734         |\n",
      "|    ep_rew_mean          | 911         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 2746        |\n",
      "|    total_timesteps      | 169124      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007986887 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0235     |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 769          |\n",
      "|    ep_rew_mean          | 878          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 2780         |\n",
      "|    total_timesteps      | 171172       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048797624 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00392     |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 10580        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 61.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 787         |\n",
      "|    ep_rew_mean          | 861         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 2812        |\n",
      "|    total_timesteps      | 173220      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008902302 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00474    |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 5.17        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=1694.00 +/- 0.00\n",
      "Episode length: 206.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 206        |\n",
      "|    mean_reward          | 1.69e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 175000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00243817 |\n",
      "|    clip_fraction        | 0.00347    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0078    |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 57.2       |\n",
      "|    n_updates            | 10600      |\n",
      "|    policy_gradient_loss | -0.00259   |\n",
      "|    value_loss           | 260        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 795      |\n",
      "|    ep_rew_mean     | 854      |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 85       |\n",
      "|    time_elapsed    | 2856     |\n",
      "|    total_timesteps | 175268   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 801        |\n",
      "|    ep_rew_mean          | 840        |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 2889       |\n",
      "|    total_timesteps      | 177316     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18554895 |\n",
      "|    clip_fraction        | 0.478      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.367     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 390        |\n",
      "|    n_updates            | 10610      |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 793        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 801          |\n",
      "|    ep_rew_mean          | 823          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 2922         |\n",
      "|    total_timesteps      | 179364       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090898685 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.005       |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 10620        |\n",
      "|    policy_gradient_loss | 0.00409      |\n",
      "|    value_loss           | 40.4         |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 688      |\n",
      "|    ep_rew_mean          | 785      |\n",
      "|    winrate              | 0        |\n",
      "| time/                   |          |\n",
      "|    fps                  | 60       |\n",
      "|    iterations           | 88       |\n",
      "|    time_elapsed         | 2955     |\n",
      "|    total_timesteps      | 181412   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 1.066575 |\n",
      "|    clip_fraction        | 0.353    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.155   |\n",
      "|    explained_variance   | 0.941    |\n",
      "|    learning_rate        | 3e-05    |\n",
      "|    loss                 | 5.91     |\n",
      "|    n_updates            | 10630    |\n",
      "|    policy_gradient_loss | -0.0222  |\n",
      "|    value_loss           | 61.8     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 630         |\n",
      "|    ep_rew_mean          | 759         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 2987        |\n",
      "|    total_timesteps      | 183460      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024823762 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 626          |\n",
      "|    ep_rew_mean          | 878          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 3020         |\n",
      "|    total_timesteps      | 185508       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122817485 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.119       |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.07e+03     |\n",
      "|    n_updates            | 10650        |\n",
      "|    policy_gradient_loss | -0.000396    |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 572         |\n",
      "|    ep_rew_mean          | 990         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 3053        |\n",
      "|    total_timesteps      | 187556      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007221413 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.128      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 783         |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | 1.07e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 3086        |\n",
      "|    total_timesteps      | 189604      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017040368 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.109      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 598         |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | 0.000146    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 606         |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 3118        |\n",
      "|    total_timesteps      | 191652      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009533597 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0971     |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | 0.00501     |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | 1.2e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 3151        |\n",
      "|    total_timesteps      | 193700      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015682993 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0318     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | 0.00728     |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 1.24e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 3183         |\n",
      "|    total_timesteps      | 195748       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078683365 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.085       |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 401          |\n",
      "|    n_updates            | 10700        |\n",
      "|    policy_gradient_loss | 0.00195      |\n",
      "|    value_loss           | 1.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 3216        |\n",
      "|    total_timesteps      | 197796      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008637937 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0301     |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | 0.00253     |\n",
      "|    value_loss           | 816         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 206         |\n",
      "|    ep_rew_mean          | 1.48e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 3249        |\n",
      "|    total_timesteps      | 199844      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010577618 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 742         |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | 0.00169     |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=1907.00 +/- 0.00\n",
      "Episode length: 225.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 225          |\n",
      "|    mean_reward          | 1.91e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053431843 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 426          |\n",
      "|    n_updates            | 10730        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    value_loss           | 1.03e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | 1.51e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 3296     |\n",
      "|    total_timesteps | 201892   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 227          |\n",
      "|    ep_rew_mean          | 1.51e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 3328         |\n",
      "|    total_timesteps      | 203940       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063796127 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0565      |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 274          |\n",
      "|    n_updates            | 10740        |\n",
      "|    policy_gradient_loss | 0.00346      |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 242          |\n",
      "|    ep_rew_mean          | 1.48e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 3360         |\n",
      "|    total_timesteps      | 205988       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048449617 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0119      |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 10750        |\n",
      "|    policy_gradient_loss | 0.00272      |\n",
      "|    value_loss           | 36.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 262         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 3392        |\n",
      "|    total_timesteps      | 208036      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016725129 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0371     |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | 0.00641     |\n",
      "|    value_loss           | 4.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 265         |\n",
      "|    ep_rew_mean          | 1.52e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 3425        |\n",
      "|    total_timesteps      | 210084      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014741026 |\n",
      "|    clip_fraction        | 0.0299      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0352     |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 282        |\n",
      "|    ep_rew_mean          | 1.52e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 3456       |\n",
      "|    total_timesteps      | 212132     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03491701 |\n",
      "|    clip_fraction        | 0.0581     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0863    |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 216        |\n",
      "|    n_updates            | 10780      |\n",
      "|    policy_gradient_loss | 0.00442    |\n",
      "|    value_loss           | 1.12e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | 1.51e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 3489        |\n",
      "|    total_timesteps      | 214180      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008927047 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0135     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 284          |\n",
      "|    ep_rew_mean          | 1.53e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 3521         |\n",
      "|    total_timesteps      | 216228       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051768627 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0616      |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 211          |\n",
      "|    n_updates            | 10800        |\n",
      "|    policy_gradient_loss | -0.000952    |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 266         |\n",
      "|    ep_rew_mean          | 1.53e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 3554        |\n",
      "|    total_timesteps      | 218276      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013247127 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0721     |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.000543   |\n",
      "|    value_loss           | 345         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 285        |\n",
      "|    ep_rew_mean          | 1.54e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 3586       |\n",
      "|    total_timesteps      | 220324     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06280545 |\n",
      "|    clip_fraction        | 0.0709     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.102     |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 611        |\n",
      "|    n_updates            | 10820      |\n",
      "|    policy_gradient_loss | -0.00337   |\n",
      "|    value_loss           | 1.28e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 279        |\n",
      "|    ep_rew_mean          | 1.49e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 108        |\n",
      "|    time_elapsed         | 3618       |\n",
      "|    total_timesteps      | 222372     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08389401 |\n",
      "|    clip_fraction        | 0.0214     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0199    |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 10830      |\n",
      "|    policy_gradient_loss | 0.00115    |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 3649        |\n",
      "|    total_timesteps      | 224420      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004303006 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0338     |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 613         |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | 0.00596     |\n",
      "|    value_loss           | 3.14e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.00e+03      |\n",
      "|    mean_reward          | -21           |\n",
      "| rollout/                |               |\n",
      "|    winrate              | 0             |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 225000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088623003 |\n",
      "|    clip_fraction        | 0.00273       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00453      |\n",
      "|    explained_variance   | 0.396         |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 799           |\n",
      "|    n_updates            | 10850         |\n",
      "|    policy_gradient_loss | -0.00046      |\n",
      "|    value_loss           | 1.64e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 296      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 110      |\n",
      "|    time_elapsed    | 3794     |\n",
      "|    total_timesteps | 226468   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 323          |\n",
      "|    ep_rew_mean          | 1.41e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 59           |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 3822         |\n",
      "|    total_timesteps      | 228516       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057523362 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0224      |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 10860        |\n",
      "|    policy_gradient_loss | 0.00148      |\n",
      "|    value_loss           | 1.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 331         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 3850        |\n",
      "|    total_timesteps      | 230564      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009081608 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0477     |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 825         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 3879        |\n",
      "|    total_timesteps      | 232612      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043333635 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.167      |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.000325   |\n",
      "|    value_loss           | 4.96e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 369       |\n",
      "|    ep_rew_mean          | 1.34e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 59        |\n",
      "|    iterations           | 114       |\n",
      "|    time_elapsed         | 3907      |\n",
      "|    total_timesteps      | 234660    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0149853 |\n",
      "|    clip_fraction        | 0.00542   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.00301  |\n",
      "|    explained_variance   | -0.456    |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 67.3      |\n",
      "|    n_updates            | 10890     |\n",
      "|    policy_gradient_loss | 0.00221   |\n",
      "|    value_loss           | 400       |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 388           |\n",
      "|    ep_rew_mean          | 1.32e+03      |\n",
      "|    winrate              | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 59            |\n",
      "|    iterations           | 115           |\n",
      "|    time_elapsed         | 3935          |\n",
      "|    total_timesteps      | 236708        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9994018e-05 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00572      |\n",
      "|    explained_variance   | 0.616         |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 16.9          |\n",
      "|    n_updates            | 10900         |\n",
      "|    policy_gradient_loss | -0.00033      |\n",
      "|    value_loss           | 563           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 389         |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 59          |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 3963        |\n",
      "|    total_timesteps      | 238756      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009346669 |\n",
      "|    clip_fraction        | 0.00264     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0049     |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 372         |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | -0.000617   |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 381       |\n",
      "|    ep_rew_mean          | 1.23e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 60        |\n",
      "|    iterations           | 117       |\n",
      "|    time_elapsed         | 3990      |\n",
      "|    total_timesteps      | 240804    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0856766 |\n",
      "|    clip_fraction        | 0.513     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.387    |\n",
      "|    explained_variance   | 0.296     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 32.3      |\n",
      "|    n_updates            | 10920     |\n",
      "|    policy_gradient_loss | -0.0105   |\n",
      "|    value_loss           | 355       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 1.21e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 4019        |\n",
      "|    total_timesteps      | 242852      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016844044 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.145      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | 0.00745     |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 317          |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 4047         |\n",
      "|    total_timesteps      | 244900       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066000214 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.142       |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 914          |\n",
      "|    n_updates            | 10940        |\n",
      "|    policy_gradient_loss | -5.87e-05    |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 313          |\n",
      "|    ep_rew_mean          | 1.08e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 4076         |\n",
      "|    total_timesteps      | 246948       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067460435 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.134       |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 624          |\n",
      "|    n_updates            | 10950        |\n",
      "|    policy_gradient_loss | -0.000477    |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 283         |\n",
      "|    ep_rew_mean          | 1.01e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 4103        |\n",
      "|    total_timesteps      | 248996      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011617314 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.128      |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.32e+03    |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=736.00 +/- 0.00\n",
      "Episode length: 76.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 76          |\n",
      "|    mean_reward          | 736         |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013730051 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.12       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 4.31e+03    |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | 0.000819    |\n",
      "|    value_loss           | 4.95e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 1.08e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 122      |\n",
      "|    time_elapsed    | 4135     |\n",
      "|    total_timesteps | 251044   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 131         |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 4163        |\n",
      "|    total_timesteps      | 253092      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011740686 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.154      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 3.08e+03    |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | 0.0015      |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 127          |\n",
      "|    ep_rew_mean          | 1.1e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 4192         |\n",
      "|    total_timesteps      | 255140       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039750854 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0865      |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 10990        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 4.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 4222        |\n",
      "|    total_timesteps      | 257188      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007944045 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.106      |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.000226   |\n",
      "|    value_loss           | 4.52e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 133        |\n",
      "|    ep_rew_mean          | 1.16e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 4251       |\n",
      "|    total_timesteps      | 259236     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08777488 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.177     |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 937        |\n",
      "|    n_updates            | 11010      |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    value_loss           | 2.6e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 4280        |\n",
      "|    total_timesteps      | 261284      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011095108 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.000414   |\n",
      "|    value_loss           | 3.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 136         |\n",
      "|    ep_rew_mean          | 1.19e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 4309        |\n",
      "|    total_timesteps      | 263332      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054820765 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 604         |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 2.12e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 1.2e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 4338        |\n",
      "|    total_timesteps      | 265380      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006458536 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0289     |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | 0.00485     |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | 1.19e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 4367        |\n",
      "|    total_timesteps      | 267428      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012703221 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0192     |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 77.2        |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | 0.00358     |\n",
      "|    value_loss           | 368         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 177         |\n",
      "|    ep_rew_mean          | 1.25e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 4395        |\n",
      "|    total_timesteps      | 269476      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025288574 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0894     |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.92e+03    |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | 0.00332     |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 178         |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 4424        |\n",
      "|    total_timesteps      | 271524      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035963833 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.126      |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 575         |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | 0.00483     |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 4457        |\n",
      "|    total_timesteps      | 273572      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012951823 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0351     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 69.9        |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.000205   |\n",
      "|    value_loss           | 467         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=1569.00 +/- 0.00\n",
      "Episode length: 174.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 174        |\n",
      "|    mean_reward          | 1.57e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 275000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09943032 |\n",
      "|    clip_fraction        | 0.0579     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0704    |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 191        |\n",
      "|    n_updates            | 11090      |\n",
      "|    policy_gradient_loss | 0.0014     |\n",
      "|    value_loss           | 1.99e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 1.36e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 134      |\n",
      "|    time_elapsed    | 4501     |\n",
      "|    total_timesteps | 275620   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 210         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 4533        |\n",
      "|    total_timesteps      | 277668      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016022239 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0907     |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 460         |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | 0.00848     |\n",
      "|    value_loss           | 1.88e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 229        |\n",
      "|    ep_rew_mean          | 1.38e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 4566       |\n",
      "|    total_timesteps      | 279716     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39311928 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.132     |\n",
      "|    explained_variance   | 0.828      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 744        |\n",
      "|    n_updates            | 11110      |\n",
      "|    policy_gradient_loss | -0.0213    |\n",
      "|    value_loss           | 1.51e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 231         |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 4600        |\n",
      "|    total_timesteps      | 281764      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010779795 |\n",
      "|    clip_fraction        | 0.0062      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00989    |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.000635   |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 4633        |\n",
      "|    total_timesteps      | 283812      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010746297 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0677     |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 588         |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 272         |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 4666        |\n",
      "|    total_timesteps      | 285860      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003946364 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0241     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 62          |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.000973   |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 272         |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 4700        |\n",
      "|    total_timesteps      | 287908      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009655314 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0408     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 4733        |\n",
      "|    total_timesteps      | 289956      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002440747 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.034      |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | 0.0027      |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 312         |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 4762        |\n",
      "|    total_timesteps      | 292004      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012995654 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0533     |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 4791        |\n",
      "|    total_timesteps      | 294052      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026606185 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0411     |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 278         |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    value_loss           | 856         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 1.48e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 4820        |\n",
      "|    total_timesteps      | 296100      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012057402 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0442     |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -2.95e-05   |\n",
      "|    value_loss           | 691         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 315         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 4848        |\n",
      "|    total_timesteps      | 298148      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010047818 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.041      |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=1331.00 +/- 0.00\n",
      "Episode length: 139.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 139        |\n",
      "|    mean_reward          | 1.33e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 300000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04299213 |\n",
      "|    clip_fraction        | 0.034      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0231    |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 11210      |\n",
      "|    policy_gradient_loss | 0.013      |\n",
      "|    value_loss           | 154        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 315      |\n",
      "|    ep_rew_mean     | 1.5e+03  |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 146      |\n",
      "|    time_elapsed    | 4883     |\n",
      "|    total_timesteps | 300196   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 315         |\n",
      "|    ep_rew_mean          | 1.5e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 4912        |\n",
      "|    total_timesteps      | 302244      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024571102 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.107      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.15e+03    |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | 0.00635     |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 315          |\n",
      "|    ep_rew_mean          | 1.49e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 4941         |\n",
      "|    total_timesteps      | 304292       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067302743 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0185      |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 270          |\n",
      "|    n_updates            | 11230        |\n",
      "|    policy_gradient_loss | 0.00181      |\n",
      "|    value_loss           | 181          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 316        |\n",
      "|    ep_rew_mean          | 1.5e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 4969       |\n",
      "|    total_timesteps      | 306340     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01638221 |\n",
      "|    clip_fraction        | 0.0578     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0881    |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 869        |\n",
      "|    n_updates            | 11240      |\n",
      "|    policy_gradient_loss | 0.00571    |\n",
      "|    value_loss           | 3.56e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 4997        |\n",
      "|    total_timesteps      | 308388      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023841273 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0426     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | 0.00462     |\n",
      "|    value_loss           | 566         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 5025        |\n",
      "|    total_timesteps      | 310436      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006584944 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0321     |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | 0.000382    |\n",
      "|    value_loss           | 808         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | 1.46e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 5056         |\n",
      "|    total_timesteps      | 312484       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072577936 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00964     |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 5            |\n",
      "|    n_updates            | 11270        |\n",
      "|    policy_gradient_loss | 0.00552      |\n",
      "|    value_loss           | 37           |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 370        |\n",
      "|    ep_rew_mean          | 1.44e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 5084       |\n",
      "|    total_timesteps      | 314532     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06524208 |\n",
      "|    clip_fraction        | 0.0719     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0625    |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 178        |\n",
      "|    n_updates            | 11280      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 603        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 366       |\n",
      "|    ep_rew_mean          | 1.42e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 61        |\n",
      "|    iterations           | 154       |\n",
      "|    time_elapsed         | 5112      |\n",
      "|    total_timesteps      | 316580    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0212898 |\n",
      "|    clip_fraction        | 0.0513    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0655   |\n",
      "|    explained_variance   | 0.933     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 1.09e+03  |\n",
      "|    n_updates            | 11290     |\n",
      "|    policy_gradient_loss | 0.00652   |\n",
      "|    value_loss           | 2.29e+03  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 357          |\n",
      "|    ep_rew_mean          | 1.4e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 5139         |\n",
      "|    total_timesteps      | 318628       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0144235855 |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.128       |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 11300        |\n",
      "|    policy_gradient_loss | 0.00231      |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 339       |\n",
      "|    ep_rew_mean          | 1.39e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 61        |\n",
      "|    iterations           | 156       |\n",
      "|    time_elapsed         | 5168      |\n",
      "|    total_timesteps      | 320676    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2973672 |\n",
      "|    clip_fraction        | 0.152     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.151    |\n",
      "|    explained_variance   | 0.759     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 1.39e+03  |\n",
      "|    n_updates            | 11310     |\n",
      "|    policy_gradient_loss | -0.00702  |\n",
      "|    value_loss           | 2.78e+03  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 356          |\n",
      "|    ep_rew_mean          | 1.36e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 5195         |\n",
      "|    total_timesteps      | 322724       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051466287 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0429      |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 254          |\n",
      "|    n_updates            | 11320        |\n",
      "|    policy_gradient_loss | 0.00171      |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 355          |\n",
      "|    ep_rew_mean          | 1.35e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 5223         |\n",
      "|    total_timesteps      | 324772       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041020676 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0276      |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 80.6         |\n",
      "|    n_updates            | 11330        |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    value_loss           | 1.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=1330.00 +/- 0.00\n",
      "Episode length: 147.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 147         |\n",
      "|    mean_reward          | 1.33e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 325000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005642304 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0129     |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 625         |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    value_loss           | 755         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 348      |\n",
      "|    ep_rew_mean     | 1.36e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 159      |\n",
      "|    time_elapsed    | 5260     |\n",
      "|    total_timesteps | 326820   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 366         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 5287        |\n",
      "|    total_timesteps      | 328868      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014349798 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0868     |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 4.53e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 382         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 5314        |\n",
      "|    total_timesteps      | 330916      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008274692 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0146     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | 0.00217     |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 366          |\n",
      "|    ep_rew_mean          | 1.35e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 5342         |\n",
      "|    total_timesteps      | 332964       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075273584 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0128      |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 11370        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    value_loss           | 251          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 5370        |\n",
      "|    total_timesteps      | 335012      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056534156 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0783     |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -2.9e-05    |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 368         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 5398        |\n",
      "|    total_timesteps      | 337060      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011937912 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0677     |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 354         |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | 0.00251     |\n",
      "|    value_loss           | 2.24e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 387         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 5425        |\n",
      "|    total_timesteps      | 339108      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253619 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0783     |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 965         |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | 0.00373     |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 5453        |\n",
      "|    total_timesteps      | 341156      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008804373 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0403     |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | 0.00193     |\n",
      "|    value_loss           | 606         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 390         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 5481        |\n",
      "|    total_timesteps      | 343204      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027025813 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0779     |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 733         |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | 0.00415     |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 390         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 5509        |\n",
      "|    total_timesteps      | 345252      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006658905 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0156     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | 0.000297    |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 5538        |\n",
      "|    total_timesteps      | 347300      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009356577 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0166     |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 43.3        |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 358         |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 5566        |\n",
      "|    total_timesteps      | 349348      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034544125 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0805     |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 583         |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=1914.00 +/- 0.00\n",
      "Episode length: 213.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 213         |\n",
      "|    mean_reward          | 1.91e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020400967 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0281     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 84.2        |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 376      |\n",
      "|    ep_rew_mean     | 1.42e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 5606     |\n",
      "|    total_timesteps | 351396   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 376         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 5635        |\n",
      "|    total_timesteps      | 353444      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004066717 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0295     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 80.3        |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.000725   |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | 1.5e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 5663        |\n",
      "|    total_timesteps      | 355492      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020525182 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0383     |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 88.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | 1.5e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 5691        |\n",
      "|    total_timesteps      | 357540      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020593327 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.054      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 71.4        |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 593         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 335        |\n",
      "|    ep_rew_mean          | 1.5e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 5720       |\n",
      "|    total_timesteps      | 359588     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03455764 |\n",
      "|    clip_fraction        | 0.0301     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0258    |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 8.89       |\n",
      "|    n_updates            | 11500      |\n",
      "|    policy_gradient_loss | -0.00356   |\n",
      "|    value_loss           | 40.5       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 277       |\n",
      "|    ep_rew_mean          | 1.48e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 62        |\n",
      "|    iterations           | 176       |\n",
      "|    time_elapsed         | 5747      |\n",
      "|    total_timesteps      | 361636    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.9373287 |\n",
      "|    clip_fraction        | 0.0986    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0622   |\n",
      "|    explained_variance   | 0.914     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 17.9      |\n",
      "|    n_updates            | 11510     |\n",
      "|    policy_gradient_loss | -0.0132   |\n",
      "|    value_loss           | 207       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 274        |\n",
      "|    ep_rew_mean          | 1.48e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 5776       |\n",
      "|    total_timesteps      | 363684     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28547513 |\n",
      "|    clip_fraction        | 0.0681     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0545    |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 2.81       |\n",
      "|    n_updates            | 11520      |\n",
      "|    policy_gradient_loss | 0.0128     |\n",
      "|    value_loss           | 79         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 251        |\n",
      "|    ep_rew_mean          | 1.46e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 5805       |\n",
      "|    total_timesteps      | 365732     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00795718 |\n",
      "|    clip_fraction        | 0.0256     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0422    |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 11530      |\n",
      "|    policy_gradient_loss | 0.00122    |\n",
      "|    value_loss           | 68         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 249          |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 5832         |\n",
      "|    total_timesteps      | 367780       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024531763 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 675          |\n",
      "|    n_updates            | 11540        |\n",
      "|    policy_gradient_loss | 0.00617      |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 224         |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 5860        |\n",
      "|    total_timesteps      | 369828      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016415458 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.145      |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | 0.00792     |\n",
      "|    value_loss           | 768         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 224         |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 5888        |\n",
      "|    total_timesteps      | 371876      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030761147 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0463     |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.000934   |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 242          |\n",
      "|    ep_rew_mean          | 1.36e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 5915         |\n",
      "|    total_timesteps      | 373924       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015283825 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00398     |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 32.8         |\n",
      "|    n_updates            | 11570        |\n",
      "|    policy_gradient_loss | 0.000775     |\n",
      "|    value_loss           | 181          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=139.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.00e+03      |\n",
      "|    mean_reward          | 139           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 375000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0179607e-05 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00171      |\n",
      "|    explained_variance   | 0.721         |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 71.3          |\n",
      "|    n_updates            | 11580         |\n",
      "|    policy_gradient_loss | 0.000102      |\n",
      "|    value_loss           | 1.13e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 1.33e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 183      |\n",
      "|    time_elapsed    | 6053     |\n",
      "|    total_timesteps | 375972   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 247          |\n",
      "|    ep_rew_mean          | 1.3e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 6082         |\n",
      "|    total_timesteps      | 378020       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042733653 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00593     |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 622          |\n",
      "|    n_updates            | 11590        |\n",
      "|    policy_gradient_loss | 0.00096      |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 263           |\n",
      "|    ep_rew_mean          | 1.27e+03      |\n",
      "|    winrate              | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 62            |\n",
      "|    iterations           | 185           |\n",
      "|    time_elapsed         | 6110          |\n",
      "|    total_timesteps      | 380068        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034553104 |\n",
      "|    clip_fraction        | 0.00645       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.009        |\n",
      "|    explained_variance   | 0.792         |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 111           |\n",
      "|    n_updates            | 11600         |\n",
      "|    policy_gradient_loss | 0.00491       |\n",
      "|    value_loss           | 664           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 240          |\n",
      "|    ep_rew_mean          | 1.23e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 6139         |\n",
      "|    total_timesteps      | 382116       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013682893 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0282      |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 86.7         |\n",
      "|    n_updates            | 11610        |\n",
      "|    policy_gradient_loss | -0.000386    |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 258         |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 6168        |\n",
      "|    total_timesteps      | 384164      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010471672 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0702     |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.00038    |\n",
      "|    value_loss           | 533         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 1.2e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 6195        |\n",
      "|    total_timesteps      | 386212      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004719218 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00146    |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | 0.00236     |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 279          |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 6224         |\n",
      "|    total_timesteps      | 388260       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046191486 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0592      |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 228          |\n",
      "|    n_updates            | 11640        |\n",
      "|    policy_gradient_loss | -0.0215      |\n",
      "|    value_loss           | 100          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 279          |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 6252         |\n",
      "|    total_timesteps      | 390308       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139582995 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 11650        |\n",
      "|    policy_gradient_loss | 0.000111     |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 6281         |\n",
      "|    total_timesteps      | 392356       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005810006 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00434     |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 5.57         |\n",
      "|    n_updates            | 11660        |\n",
      "|    policy_gradient_loss | 0.00232      |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 299         |\n",
      "|    ep_rew_mean          | 1.19e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 6309        |\n",
      "|    total_timesteps      | 394404      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014876161 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0751     |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | 0.00372     |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 280        |\n",
      "|    ep_rew_mean          | 1.2e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 6338       |\n",
      "|    total_timesteps      | 396452     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06753509 |\n",
      "|    clip_fraction        | 0.0744     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0877    |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 11680      |\n",
      "|    policy_gradient_loss | -0.00237   |\n",
      "|    value_loss           | 71.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 233         |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 6366        |\n",
      "|    total_timesteps      | 398500      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009097714 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.106      |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=1342.00 +/- 0.00\n",
      "Episode length: 147.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 147         |\n",
      "|    mean_reward          | 1.34e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013946086 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0975     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 7.77        |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | 0.000935    |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 1.28e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 195      |\n",
      "|    time_elapsed    | 6404     |\n",
      "|    total_timesteps | 400548   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 157         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 6432        |\n",
      "|    total_timesteps      | 402596      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012999207 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.101      |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 6461        |\n",
      "|    total_timesteps      | 404644      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742655 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0939     |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 6.98        |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 6489        |\n",
      "|    total_timesteps      | 406692      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554256 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0972     |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 7.55        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | 0.00322     |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 6517        |\n",
      "|    total_timesteps      | 408740      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009238447 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0903     |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 6546        |\n",
      "|    total_timesteps      | 410788      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007636682 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0853     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.000292   |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 141          |\n",
      "|    ep_rew_mean          | 1.34e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 6574         |\n",
      "|    total_timesteps      | 412836       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065453798 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.101       |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 11760        |\n",
      "|    policy_gradient_loss | 0.00509      |\n",
      "|    value_loss           | 176          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 158         |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 6603        |\n",
      "|    total_timesteps      | 414884      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013964132 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.023      |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 158          |\n",
      "|    ep_rew_mean          | 1.32e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 6630         |\n",
      "|    total_timesteps      | 416932       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034826123 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.071       |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 358          |\n",
      "|    n_updates            | 11780        |\n",
      "|    policy_gradient_loss | -9.85e-05    |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 6658        |\n",
      "|    total_timesteps      | 418980      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007932251 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | 2.55e-05    |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 6687        |\n",
      "|    total_timesteps      | 421028      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011703953 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.15       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | 0.00554     |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 6715        |\n",
      "|    total_timesteps      | 423076      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010491718 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0778     |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | 0.000518    |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=1350.00 +/- 0.00\n",
      "Episode length: 137.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 137         |\n",
      "|    mean_reward          | 1.35e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 425000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016323926 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0753     |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | 0.000327    |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 175      |\n",
      "|    ep_rew_mean     | 1.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 207      |\n",
      "|    time_elapsed    | 6751     |\n",
      "|    total_timesteps | 425124   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 6779        |\n",
      "|    total_timesteps      | 427172      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003132175 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0237     |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | 0.00173     |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 212         |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 6806        |\n",
      "|    total_timesteps      | 429220      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004980228 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0174     |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | 0.00455     |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 232         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 6834        |\n",
      "|    total_timesteps      | 431268      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076164 |\n",
      "|    clip_fraction        | 0.0224      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0378     |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | 0.00271     |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 250         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 6862        |\n",
      "|    total_timesteps      | 433316      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011274897 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0514     |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | 0.000902    |\n",
      "|    value_loss           | 557         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 6889        |\n",
      "|    total_timesteps      | 435364      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004612146 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0119     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 4.98        |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 290         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 6917        |\n",
      "|    total_timesteps      | 437412      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.107623026 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.107      |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 6945        |\n",
      "|    total_timesteps      | 439460      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006594492 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0249     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 6972        |\n",
      "|    total_timesteps      | 441508      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011697006 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0299     |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    value_loss           | 430         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 7000        |\n",
      "|    total_timesteps      | 443556      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017806116 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0432     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | 0.000894    |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 7027        |\n",
      "|    total_timesteps      | 445604      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011606868 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0448     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 350        |\n",
      "|    ep_rew_mean          | 1.42e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 218        |\n",
      "|    time_elapsed         | 7056       |\n",
      "|    total_timesteps      | 447652     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07614405 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.297     |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 42.5       |\n",
      "|    n_updates            | 11930      |\n",
      "|    policy_gradient_loss | -0.00845   |\n",
      "|    value_loss           | 447        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 7085        |\n",
      "|    total_timesteps      | 449700      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006428506 |\n",
      "|    clip_fraction        | 0.00923     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0103     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.000452   |\n",
      "|    value_loss           | 41.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=1675.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.00e+03    |\n",
      "|    mean_reward          | 1.68e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011915617 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0481     |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 362      |\n",
      "|    ep_rew_mean     | 1.46e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 7226     |\n",
      "|    total_timesteps | 451748   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 382          |\n",
      "|    ep_rew_mean          | 1.47e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 7253         |\n",
      "|    total_timesteps      | 453796       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092535205 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0124      |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 3.36e+03     |\n",
      "|    n_updates            | 11960        |\n",
      "|    policy_gradient_loss | -0.000351    |\n",
      "|    value_loss           | 3.96e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 1.48e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 7280        |\n",
      "|    total_timesteps      | 455844      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010240041 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0179     |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 80.8        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 487         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 421          |\n",
      "|    ep_rew_mean          | 1.49e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 7307         |\n",
      "|    total_timesteps      | 457892       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069265775 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0107      |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 4.01         |\n",
      "|    n_updates            | 11980        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 440         |\n",
      "|    ep_rew_mean          | 1.5e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 7334        |\n",
      "|    total_timesteps      | 459940      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011670375 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0422     |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 405         |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | 0.0029      |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 458          |\n",
      "|    ep_rew_mean          | 1.5e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 225          |\n",
      "|    time_elapsed         | 7360         |\n",
      "|    total_timesteps      | 461988       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007191184 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00986     |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 12000        |\n",
      "|    policy_gradient_loss | 0.00125      |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 477          |\n",
      "|    ep_rew_mean          | 1.5e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 7387         |\n",
      "|    total_timesteps      | 464036       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019341784 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00924     |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 4.16         |\n",
      "|    n_updates            | 12010        |\n",
      "|    policy_gradient_loss | 0.00158      |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 477          |\n",
      "|    ep_rew_mean          | 1.51e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 7414         |\n",
      "|    total_timesteps      | 466084       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020245814 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0125      |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 6.93         |\n",
      "|    n_updates            | 12020        |\n",
      "|    policy_gradient_loss | -0.000738    |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 496           |\n",
      "|    ep_rew_mean          | 1.52e+03      |\n",
      "|    winrate              | 0             |\n",
      "| time/                   |               |\n",
      "|    fps                  | 62            |\n",
      "|    iterations           | 228           |\n",
      "|    time_elapsed         | 7442          |\n",
      "|    total_timesteps      | 468132        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086453126 |\n",
      "|    clip_fraction        | 0.00493       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00783      |\n",
      "|    explained_variance   | 0.998         |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 10            |\n",
      "|    n_updates            | 12030         |\n",
      "|    policy_gradient_loss | 0.00157       |\n",
      "|    value_loss           | 11.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 518         |\n",
      "|    ep_rew_mean          | 1.54e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 7469        |\n",
      "|    total_timesteps      | 470180      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008568405 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0187     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 1.55e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 7496        |\n",
      "|    total_timesteps      | 472228      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009289998 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0288     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | 0.00899     |\n",
      "|    value_loss           | 451         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 538          |\n",
      "|    ep_rew_mean          | 1.56e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 7523         |\n",
      "|    total_timesteps      | 474276       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013116968 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00888     |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 4.13         |\n",
      "|    n_updates            | 12060        |\n",
      "|    policy_gradient_loss | -0.000827    |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=1862.00 +/- 0.00\n",
      "Episode length: 191.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 191         |\n",
      "|    mean_reward          | 1.86e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 475000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017442811 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0262     |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | 0.00501     |\n",
      "|    value_loss           | 437         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 559      |\n",
      "|    ep_rew_mean     | 1.59e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 232      |\n",
      "|    time_elapsed    | 7560     |\n",
      "|    total_timesteps | 476324   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | 1.59e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 7587        |\n",
      "|    total_timesteps      | 478372      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024060896 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0215     |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | 0.000947    |\n",
      "|    value_loss           | 1.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 597         |\n",
      "|    ep_rew_mean          | 1.6e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 7614        |\n",
      "|    total_timesteps      | 480420      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006415015 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00904    |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.000972   |\n",
      "|    value_loss           | 32.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 613        |\n",
      "|    ep_rew_mean          | 1.57e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 235        |\n",
      "|    time_elapsed         | 7641       |\n",
      "|    total_timesteps      | 482468     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02053067 |\n",
      "|    clip_fraction        | 0.0262     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0284    |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 19.5       |\n",
      "|    n_updates            | 12100      |\n",
      "|    policy_gradient_loss | -0.00273   |\n",
      "|    value_loss           | 270        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 631         |\n",
      "|    ep_rew_mean          | 1.58e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 7668        |\n",
      "|    total_timesteps      | 484516      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013024539 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0131     |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 644         |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | 0.00331     |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 651        |\n",
      "|    ep_rew_mean          | 1.59e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 237        |\n",
      "|    time_elapsed         | 7695       |\n",
      "|    total_timesteps      | 486564     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01578918 |\n",
      "|    clip_fraction        | 0.00918    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00795   |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 12120      |\n",
      "|    policy_gradient_loss | -0.000386  |\n",
      "|    value_loss           | 77         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 670        |\n",
      "|    ep_rew_mean          | 1.59e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 7722       |\n",
      "|    total_timesteps      | 488612     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05304375 |\n",
      "|    clip_fraction        | 0.0309     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0323    |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 21.1       |\n",
      "|    n_updates            | 12130      |\n",
      "|    policy_gradient_loss | -0.00505   |\n",
      "|    value_loss           | 289        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | 1.59e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 7749        |\n",
      "|    total_timesteps      | 490660      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009661032 |\n",
      "|    clip_fraction        | 0.00967     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00832    |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 4.04        |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 709        |\n",
      "|    ep_rew_mean          | 1.6e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 7776       |\n",
      "|    total_timesteps      | 492708     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03570585 |\n",
      "|    clip_fraction        | 0.0156     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00742   |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 14.4       |\n",
      "|    n_updates            | 12150      |\n",
      "|    policy_gradient_loss | 0.0331     |\n",
      "|    value_loss           | 37.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 711         |\n",
      "|    ep_rew_mean          | 1.61e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 7803        |\n",
      "|    total_timesteps      | 494756      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071515925 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0426     |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 731         |\n",
      "|    ep_rew_mean          | 1.63e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 7830        |\n",
      "|    total_timesteps      | 496804      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011831533 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0373     |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 494         |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | 0.005       |\n",
      "|    value_loss           | 998         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 731         |\n",
      "|    ep_rew_mean          | 1.61e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 7857        |\n",
      "|    total_timesteps      | 498852      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005381319 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0312     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 372         |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.000474   |\n",
      "|    value_loss           | 849         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=1693.00 +/- 0.00\n",
      "Episode length: 192.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 192         |\n",
      "|    mean_reward          | 1.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010129002 |\n",
      "|    clip_fraction        | 0.00747     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00714    |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 3.68        |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 730      |\n",
      "|    ep_rew_mean     | 1.63e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 244      |\n",
      "|    time_elapsed    | 7896     |\n",
      "|    total_timesteps | 500900   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 730          |\n",
      "|    ep_rew_mean          | 1.63e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 245          |\n",
      "|    time_elapsed         | 7922         |\n",
      "|    total_timesteps      | 502948       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042793476 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0281      |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 297          |\n",
      "|    n_updates            | 12200        |\n",
      "|    policy_gradient_loss | -0.000685    |\n",
      "|    value_loss           | 3.41e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 748         |\n",
      "|    ep_rew_mean          | 1.63e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 7950        |\n",
      "|    total_timesteps      | 504996      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030065268 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 765          |\n",
      "|    ep_rew_mean          | 1.61e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 7976         |\n",
      "|    total_timesteps      | 507044       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010491862 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00714     |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.86         |\n",
      "|    n_updates            | 12220        |\n",
      "|    policy_gradient_loss | 0.000233     |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 765          |\n",
      "|    ep_rew_mean          | 1.61e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 8003         |\n",
      "|    total_timesteps      | 509092       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033230807 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0122      |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 12230        |\n",
      "|    policy_gradient_loss | 0.000353     |\n",
      "|    value_loss           | 1.07e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 766         |\n",
      "|    ep_rew_mean          | 1.61e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 8030        |\n",
      "|    total_timesteps      | 511140      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002382142 |\n",
      "|    clip_fraction        | 0.0062      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00638    |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 3.7         |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 704        |\n",
      "|    ep_rew_mean          | 1.5e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 250        |\n",
      "|    time_elapsed         | 8057       |\n",
      "|    total_timesteps      | 513188     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12354738 |\n",
      "|    clip_fraction        | 0.0228     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0121    |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 6.17       |\n",
      "|    n_updates            | 12250      |\n",
      "|    policy_gradient_loss | -0.00392   |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 723         |\n",
      "|    ep_rew_mean          | 1.5e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 8085        |\n",
      "|    total_timesteps      | 515236      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028241929 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0955     |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 6.48e+03    |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | 0.00812     |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 685          |\n",
      "|    ep_rew_mean          | 1.47e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 8112         |\n",
      "|    total_timesteps      | 517284       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051264204 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.018       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 12270        |\n",
      "|    policy_gradient_loss | -0.000545    |\n",
      "|    value_loss           | 66           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | 1.41e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 8140        |\n",
      "|    total_timesteps      | 519332      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047805727 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0886     |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    value_loss           | 3.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 632         |\n",
      "|    ep_rew_mean          | 1.4e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 8168        |\n",
      "|    total_timesteps      | 521380      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004445323 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0479     |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 938         |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    value_loss           | 4.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 650          |\n",
      "|    ep_rew_mean          | 1.4e+03      |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 8196         |\n",
      "|    total_timesteps      | 523428       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068239635 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0262      |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 184          |\n",
      "|    n_updates            | 12300        |\n",
      "|    policy_gradient_loss | -0.000237    |\n",
      "|    value_loss           | 924          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=1696.00 +/- 0.00\n",
      "Episode length: 183.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 183         |\n",
      "|    mean_reward          | 1.7e+03     |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 525000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012900531 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.019      |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 54.8        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.000963   |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 622      |\n",
      "|    ep_rew_mean     | 1.41e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 256      |\n",
      "|    time_elapsed    | 8236     |\n",
      "|    total_timesteps | 525476   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 602          |\n",
      "|    ep_rew_mean          | 1.39e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 8265         |\n",
      "|    total_timesteps      | 527524       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066087265 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0376      |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 547          |\n",
      "|    n_updates            | 12320        |\n",
      "|    policy_gradient_loss | 0.000883     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 569        |\n",
      "|    ep_rew_mean          | 1.36e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 258        |\n",
      "|    time_elapsed         | 8294       |\n",
      "|    total_timesteps      | 529572     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06121015 |\n",
      "|    clip_fraction        | 0.0192     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00962   |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 144        |\n",
      "|    n_updates            | 12330      |\n",
      "|    policy_gradient_loss | 0.01       |\n",
      "|    value_loss           | 1e+03      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 497         |\n",
      "|    ep_rew_mean          | 1.33e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 8324        |\n",
      "|    total_timesteps      | 531620      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.075555354 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 499         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 8353        |\n",
      "|    total_timesteps      | 533668      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013761512 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0839     |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | 0.00628     |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 430         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 8382        |\n",
      "|    total_timesteps      | 535716      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010005312 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0136     |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 60.9        |\n",
      "|    n_updates            | 12360       |\n",
      "|    policy_gradient_loss | 0.0024      |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 448         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 8411        |\n",
      "|    total_timesteps      | 537764      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042110234 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0966     |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 549         |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 449         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 8440        |\n",
      "|    total_timesteps      | 539812      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020030439 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0097     |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | 0.000158    |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 468         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 8468        |\n",
      "|    total_timesteps      | 541860      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052521415 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0543     |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 475         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 435          |\n",
      "|    ep_rew_mean          | 1.37e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 8496         |\n",
      "|    total_timesteps      | 543908       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035578115 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00789     |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.24         |\n",
      "|    n_updates            | 12400        |\n",
      "|    policy_gradient_loss | 0.0018       |\n",
      "|    value_loss           | 26.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 453        |\n",
      "|    ep_rew_mean          | 1.38e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 266        |\n",
      "|    time_elapsed         | 8525       |\n",
      "|    total_timesteps      | 545956     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06149096 |\n",
      "|    clip_fraction        | 0.0739     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0524    |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 324        |\n",
      "|    n_updates            | 12410      |\n",
      "|    policy_gradient_loss | 0.0178     |\n",
      "|    value_loss           | 592        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 453         |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 8552        |\n",
      "|    total_timesteps      | 548004      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003519498 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.018      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | 0.000213    |\n",
      "|    value_loss           | 62.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=1691.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.00e+03    |\n",
      "|    mean_reward          | 1.69e+03    |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003322049 |\n",
      "|    clip_fraction        | 0.00659     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00808    |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.000858   |\n",
      "|    value_loss           | 31.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 434      |\n",
      "|    ep_rew_mean     | 1.37e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 268      |\n",
      "|    time_elapsed    | 8689     |\n",
      "|    total_timesteps | 550052   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 214         |\n",
      "|    ep_rew_mean          | 749         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 8717        |\n",
      "|    total_timesteps      | 552100      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011611965 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.023      |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | 0.000494    |\n",
      "|    value_loss           | 1.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 184         |\n",
      "|    ep_rew_mean          | 659         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 8745        |\n",
      "|    total_timesteps      | 554148      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029908057 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.074      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 346         |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | 0.0239      |\n",
      "|    value_loss           | 6.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60.4        |\n",
      "|    ep_rew_mean          | 362         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 8773        |\n",
      "|    total_timesteps      | 556196      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028361918 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0214     |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.8        |\n",
      "|    ep_rew_mean          | 475         |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 8801        |\n",
      "|    total_timesteps      | 558244      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040030755 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0971     |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.98e+03    |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | 0.0012      |\n",
      "|    value_loss           | 8.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 90.9       |\n",
      "|    ep_rew_mean          | 583        |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 8829       |\n",
      "|    total_timesteps      | 560292     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04164222 |\n",
      "|    clip_fraction        | 0.0912     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0892    |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 2.34e+03   |\n",
      "|    n_updates            | 12480      |\n",
      "|    policy_gradient_loss | 0.0137     |\n",
      "|    value_loss           | 3.66e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 106        |\n",
      "|    ep_rew_mean          | 698        |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 274        |\n",
      "|    time_elapsed         | 8857       |\n",
      "|    total_timesteps      | 562340     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01924552 |\n",
      "|    clip_fraction        | 0.0775     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0941    |\n",
      "|    explained_variance   | 0.752      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 6.09e+03   |\n",
      "|    n_updates            | 12490      |\n",
      "|    policy_gradient_loss | 0.0013     |\n",
      "|    value_loss           | 6.53e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 124        |\n",
      "|    ep_rew_mean          | 829        |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 275        |\n",
      "|    time_elapsed         | 8885       |\n",
      "|    total_timesteps      | 564388     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01427383 |\n",
      "|    clip_fraction        | 0.0616     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0947    |\n",
      "|    explained_variance   | 0.846      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 487        |\n",
      "|    n_updates            | 12500      |\n",
      "|    policy_gradient_loss | 0.00343    |\n",
      "|    value_loss           | 2.5e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 141          |\n",
      "|    ep_rew_mean          | 960          |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 276          |\n",
      "|    time_elapsed         | 8913         |\n",
      "|    total_timesteps      | 566436       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070194993 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0977      |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 206          |\n",
      "|    n_updates            | 12510        |\n",
      "|    policy_gradient_loss | 0.00119      |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 134         |\n",
      "|    ep_rew_mean          | 1.04e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 8941        |\n",
      "|    total_timesteps      | 568484      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009389345 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0988     |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | 0.000322    |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 142          |\n",
      "|    ep_rew_mean          | 1.11e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 8969         |\n",
      "|    total_timesteps      | 570532       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097080665 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.109       |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 516          |\n",
      "|    n_updates            | 12530        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 2.25e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 167        |\n",
      "|    ep_rew_mean          | 1.14e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 279        |\n",
      "|    time_elapsed         | 8996       |\n",
      "|    total_timesteps      | 572580     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00614963 |\n",
      "|    clip_fraction        | 0.0428     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0814    |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 64.7       |\n",
      "|    n_updates            | 12540      |\n",
      "|    policy_gradient_loss | 3.53e-05   |\n",
      "|    value_loss           | 264        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 176        |\n",
      "|    ep_rew_mean          | 1.21e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 9025       |\n",
      "|    total_timesteps      | 574628     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00641549 |\n",
      "|    clip_fraction        | 0.0175     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0265    |\n",
      "|    explained_variance   | 0.853      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 12550      |\n",
      "|    policy_gradient_loss | 0.00311    |\n",
      "|    value_loss           | 724        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=-21.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.00e+03    |\n",
      "|    mean_reward          | -21         |\n",
      "| rollout/                |             |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 575000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012883691 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.112      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 28.5        |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 181      |\n",
      "|    ep_rew_mean     | 1.25e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 281      |\n",
      "|    time_elapsed    | 9163     |\n",
      "|    total_timesteps | 576676   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 186         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 9191        |\n",
      "|    total_timesteps      | 578724      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023189098 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.122      |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 447         |\n",
      "|    n_updates            | 12570       |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    value_loss           | 2.08e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 1.35e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 9219        |\n",
      "|    total_timesteps      | 580772      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016958341 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 2.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 9247        |\n",
      "|    total_timesteps      | 582820      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019633962 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0863     |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 584         |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    value_loss           | 914         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 186         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 9275        |\n",
      "|    total_timesteps      | 584868      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012545613 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0992     |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.25e+03    |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 202        |\n",
      "|    ep_rew_mean          | 1.36e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 286        |\n",
      "|    time_elapsed         | 9303       |\n",
      "|    total_timesteps      | 586916     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00671968 |\n",
      "|    clip_fraction        | 0.0409     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0775    |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 526        |\n",
      "|    n_updates            | 12610      |\n",
      "|    policy_gradient_loss | -8.64e-05  |\n",
      "|    value_loss           | 1.55e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 218          |\n",
      "|    ep_rew_mean          | 1.36e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 9330         |\n",
      "|    total_timesteps      | 588964       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057091936 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0356      |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.1e+03      |\n",
      "|    n_updates            | 12620        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 900          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 220         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 9358        |\n",
      "|    total_timesteps      | 591012      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015887495 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0335     |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | 0.00105     |\n",
      "|    value_loss           | 797         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 237        |\n",
      "|    ep_rew_mean          | 1.38e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 289        |\n",
      "|    time_elapsed         | 9386       |\n",
      "|    total_timesteps      | 593060     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01935731 |\n",
      "|    clip_fraction        | 0.0339     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.04      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 61         |\n",
      "|    n_updates            | 12640      |\n",
      "|    policy_gradient_loss | 0.00416    |\n",
      "|    value_loss           | 212        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 256        |\n",
      "|    ep_rew_mean          | 1.39e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 290        |\n",
      "|    time_elapsed         | 9413       |\n",
      "|    total_timesteps      | 595108     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00671283 |\n",
      "|    clip_fraction        | 0.0294     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0337    |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 73.8       |\n",
      "|    n_updates            | 12650      |\n",
      "|    policy_gradient_loss | -0.00064   |\n",
      "|    value_loss           | 1.2e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 272        |\n",
      "|    ep_rew_mean          | 1.38e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 291        |\n",
      "|    time_elapsed         | 9441       |\n",
      "|    total_timesteps      | 597156     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08154209 |\n",
      "|    clip_fraction        | 0.06       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0665    |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 207        |\n",
      "|    n_updates            | 12660      |\n",
      "|    policy_gradient_loss | -0.000492  |\n",
      "|    value_loss           | 489        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 291         |\n",
      "|    ep_rew_mean          | 1.39e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 9469        |\n",
      "|    total_timesteps      | 599204      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006485833 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0283     |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=1567.00 +/- 0.00\n",
      "Episode length: 172.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 172        |\n",
      "|    mean_reward          | 1.57e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 600000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20246834 |\n",
      "|    clip_fraction        | 0.0456     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.043     |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 12680      |\n",
      "|    policy_gradient_loss | 0.00126    |\n",
      "|    value_loss           | 93.3       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 276      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 9507     |\n",
      "|    total_timesteps | 601252   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 9535        |\n",
      "|    total_timesteps      | 603300      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046886012 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.161      |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 349         |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | 0.00296     |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 296         |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 9563        |\n",
      "|    total_timesteps      | 605348      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010168698 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0398     |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | -0.000169   |\n",
      "|    value_loss           | 777         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 9591        |\n",
      "|    total_timesteps      | 607396      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006128921 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0249     |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 35          |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 9619        |\n",
      "|    total_timesteps      | 609444      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013576045 |\n",
      "|    clip_fraction        | 0.0299      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0496     |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 506         |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | 0.00405     |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 9647        |\n",
      "|    total_timesteps      | 611492      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017643627 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0286     |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 87.1        |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.000371   |\n",
      "|    value_loss           | 709         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 350        |\n",
      "|    ep_rew_mean          | 1.46e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 299        |\n",
      "|    time_elapsed         | 9675       |\n",
      "|    total_timesteps      | 613540     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06960273 |\n",
      "|    clip_fraction        | 0.0526     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0447    |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 114        |\n",
      "|    n_updates            | 12740      |\n",
      "|    policy_gradient_loss | -0.00454   |\n",
      "|    value_loss           | 155        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 9702        |\n",
      "|    total_timesteps      | 615588      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065562405 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0445     |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 784         |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | 0.003       |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 387         |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 9730        |\n",
      "|    total_timesteps      | 617636      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015128621 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0217     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 30.1        |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 9759        |\n",
      "|    total_timesteps      | 619684      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006944428 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0514     |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 12770       |\n",
      "|    policy_gradient_loss | 0.00214     |\n",
      "|    value_loss           | 1.1e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 407       |\n",
      "|    ep_rew_mean          | 1.49e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 63        |\n",
      "|    iterations           | 303       |\n",
      "|    time_elapsed         | 9786      |\n",
      "|    total_timesteps      | 621732    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0377228 |\n",
      "|    clip_fraction        | 0.0733    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0763   |\n",
      "|    explained_variance   | 0.964     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 225       |\n",
      "|    n_updates            | 12780     |\n",
      "|    policy_gradient_loss | 0.00424   |\n",
      "|    value_loss           | 1.02e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 425        |\n",
      "|    ep_rew_mean          | 1.49e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 304        |\n",
      "|    time_elapsed         | 9814       |\n",
      "|    total_timesteps      | 623780     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02656121 |\n",
      "|    clip_fraction        | 0.0191     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0218    |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 12790      |\n",
      "|    policy_gradient_loss | -0.00221   |\n",
      "|    value_loss           | 234        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=1691.00 +/- 0.00\n",
      "Episode length: 192.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 192          |\n",
      "|    mean_reward          | 1.69e+03     |\n",
      "| rollout/                |              |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 625000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075679547 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0178      |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 27.5         |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | 0.000265     |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 449      |\n",
      "|    ep_rew_mean     | 1.53e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 305      |\n",
      "|    time_elapsed    | 9852     |\n",
      "|    total_timesteps | 625828   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 467         |\n",
      "|    ep_rew_mean          | 1.53e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 9880        |\n",
      "|    total_timesteps      | 627876      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008477309 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0649     |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.000732   |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 468          |\n",
      "|    ep_rew_mean          | 1.53e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 307          |\n",
      "|    time_elapsed         | 9907         |\n",
      "|    total_timesteps      | 629924       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033821883 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0134      |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 552          |\n",
      "|    n_updates            | 12820        |\n",
      "|    policy_gradient_loss | -0.000977    |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 486          |\n",
      "|    ep_rew_mean          | 1.53e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 308          |\n",
      "|    time_elapsed         | 9934         |\n",
      "|    total_timesteps      | 631972       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029091758 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0242      |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 74.1         |\n",
      "|    n_updates            | 12830        |\n",
      "|    policy_gradient_loss | -0.000152    |\n",
      "|    value_loss           | 222          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 1.53e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 9962         |\n",
      "|    total_timesteps      | 634020       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017803346 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0152      |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 8.71         |\n",
      "|    n_updates            | 12840        |\n",
      "|    policy_gradient_loss | 0.00103      |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 525        |\n",
      "|    ep_rew_mean          | 1.55e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 310        |\n",
      "|    time_elapsed         | 9990       |\n",
      "|    total_timesteps      | 636068     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.38655263 |\n",
      "|    clip_fraction        | 0.0563     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0568    |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 41.2       |\n",
      "|    n_updates            | 12850      |\n",
      "|    policy_gradient_loss | -0.00423   |\n",
      "|    value_loss           | 187        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 544         |\n",
      "|    ep_rew_mean          | 1.56e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 10017       |\n",
      "|    total_timesteps      | 638116      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010464188 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.03       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 236         |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | 0.00574     |\n",
      "|    value_loss           | 770         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 562          |\n",
      "|    ep_rew_mean          | 1.57e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 10045        |\n",
      "|    total_timesteps      | 640164       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026384883 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0281      |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 12870        |\n",
      "|    policy_gradient_loss | 0.00226      |\n",
      "|    value_loss           | 695          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 581       |\n",
      "|    ep_rew_mean          | 1.57e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 63        |\n",
      "|    iterations           | 313       |\n",
      "|    time_elapsed         | 10073     |\n",
      "|    total_timesteps      | 642212    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4964043 |\n",
      "|    clip_fraction        | 0.271     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.202    |\n",
      "|    explained_variance   | 0.992     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 107       |\n",
      "|    n_updates            | 12880     |\n",
      "|    policy_gradient_loss | -0.00794  |\n",
      "|    value_loss           | 188       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 600          |\n",
      "|    ep_rew_mean          | 1.58e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 10100        |\n",
      "|    total_timesteps      | 644260       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013430768 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0161      |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 21.8         |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | 0.00157      |\n",
      "|    value_loss           | 64.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 619          |\n",
      "|    ep_rew_mean          | 1.58e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 315          |\n",
      "|    time_elapsed         | 10128        |\n",
      "|    total_timesteps      | 646308       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029302523 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0128      |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 12900        |\n",
      "|    policy_gradient_loss | 0.00142      |\n",
      "|    value_loss           | 64.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 620          |\n",
      "|    ep_rew_mean          | 1.59e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 10155        |\n",
      "|    total_timesteps      | 648356       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028947587 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0167      |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 12910        |\n",
      "|    policy_gradient_loss | 0.00269      |\n",
      "|    value_loss           | 38.3         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=1418.00 +/- 0.00\n",
      "Episode length: 155.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 155          |\n",
      "|    mean_reward          | 1.42e+03     |\n",
      "| rollout/                |              |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 650000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069047734 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0128      |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 101          |\n",
      "|    n_updates            | 12920        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 405          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 618      |\n",
      "|    ep_rew_mean     | 1.61e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 317      |\n",
      "|    time_elapsed    | 10191    |\n",
      "|    total_timesteps | 650404   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 619          |\n",
      "|    ep_rew_mean          | 1.62e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 10218        |\n",
      "|    total_timesteps      | 652452       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036956803 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0327      |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.23e+03     |\n",
      "|    n_updates            | 12930        |\n",
      "|    policy_gradient_loss | -0.000683    |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 619         |\n",
      "|    ep_rew_mean          | 1.62e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 10246       |\n",
      "|    total_timesteps      | 654500      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012301131 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0411     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 283         |\n",
      "|    n_updates            | 12940       |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    value_loss           | 967         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 638         |\n",
      "|    ep_rew_mean          | 1.63e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 10273       |\n",
      "|    total_timesteps      | 656548      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005767719 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0253     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 58.4        |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 489         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 638         |\n",
      "|    ep_rew_mean          | 1.63e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 10301       |\n",
      "|    total_timesteps      | 658596      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011140949 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.031      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | 0.00276     |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 656       |\n",
      "|    ep_rew_mean          | 1.63e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 63        |\n",
      "|    iterations           | 322       |\n",
      "|    time_elapsed         | 10328     |\n",
      "|    total_timesteps      | 660644    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3103661 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.146    |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 4.32      |\n",
      "|    n_updates            | 12970     |\n",
      "|    policy_gradient_loss | -0.000717 |\n",
      "|    value_loss           | 24.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 674         |\n",
      "|    ep_rew_mean          | 1.63e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 10356       |\n",
      "|    total_timesteps      | 662692      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002772239 |\n",
      "|    clip_fraction        | 0.00864     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0145     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.000464   |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 675        |\n",
      "|    ep_rew_mean          | 1.63e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 324        |\n",
      "|    time_elapsed         | 10383      |\n",
      "|    total_timesteps      | 664740     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13896842 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0912    |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 3.18       |\n",
      "|    n_updates            | 12990      |\n",
      "|    policy_gradient_loss | -0.032     |\n",
      "|    value_loss           | 17.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 676         |\n",
      "|    ep_rew_mean          | 1.64e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 10411       |\n",
      "|    total_timesteps      | 666788      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007831118 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0423     |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 694         |\n",
      "|    ep_rew_mean          | 1.64e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 10438       |\n",
      "|    total_timesteps      | 668836      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012263275 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0661     |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | 0.00545     |\n",
      "|    value_loss           | 885         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 713         |\n",
      "|    ep_rew_mean          | 1.65e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 10466       |\n",
      "|    total_timesteps      | 670884      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008827132 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0145     |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | 0.000726    |\n",
      "|    value_loss           | 40.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 666         |\n",
      "|    ep_rew_mean          | 1.6e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 10493       |\n",
      "|    total_timesteps      | 672932      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019188307 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.029      |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 627         |\n",
      "|    ep_rew_mean          | 1.57e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 10521       |\n",
      "|    total_timesteps      | 674980      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020714808 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.114      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.59e+03    |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    value_loss           | 8.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=236.00 +/- 0.00\n",
      "Episode length: 31.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 31         |\n",
      "|    mean_reward          | 236        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 675000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07972883 |\n",
      "|    clip_fraction        | 0.0888     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0853    |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.04e+03   |\n",
      "|    n_updates            | 13050      |\n",
      "|    policy_gradient_loss | 0.051      |\n",
      "|    value_loss           | 4.83e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 523      |\n",
      "|    ep_rew_mean     | 1.4e+03  |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 330      |\n",
      "|    time_elapsed    | 10551    |\n",
      "|    total_timesteps | 677028   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 536         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 10579       |\n",
      "|    total_timesteps      | 679076      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031172156 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0917     |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | 0.0047      |\n",
      "|    value_loss           | 1.13e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 462         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 10607       |\n",
      "|    total_timesteps      | 681124      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011318357 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0402     |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 370         |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | 0.00668     |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 10636       |\n",
      "|    total_timesteps      | 683172      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043673176 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.152      |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.43e+03    |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | 0.00394     |\n",
      "|    value_loss           | 4.81e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 343       |\n",
      "|    ep_rew_mean          | 1.3e+03   |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 64        |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 10665     |\n",
      "|    total_timesteps      | 685220    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2608337 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.291    |\n",
      "|    explained_variance   | 0.888     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 596       |\n",
      "|    n_updates            | 13090     |\n",
      "|    policy_gradient_loss | -0.0185   |\n",
      "|    value_loss           | 1.21e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 10694       |\n",
      "|    total_timesteps      | 687268      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019611403 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0915     |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 4.36e+03    |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 10723       |\n",
      "|    total_timesteps      | 689316      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007374054 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0395     |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 40.8        |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | 0.000297    |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 307         |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 10752       |\n",
      "|    total_timesteps      | 691364      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006979171 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0354     |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.000782   |\n",
      "|    value_loss           | 251         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 267         |\n",
      "|    ep_rew_mean          | 1.27e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 10780       |\n",
      "|    total_timesteps      | 693412      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052390985 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.131      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | 0.00285     |\n",
      "|    value_loss           | 1.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 268          |\n",
      "|    ep_rew_mean          | 1.28e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 339          |\n",
      "|    time_elapsed         | 10808        |\n",
      "|    total_timesteps      | 695460       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101361545 |\n",
      "|    clip_fraction        | 0.0878       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.281       |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.55e+03     |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | 0.00231      |\n",
      "|    value_loss           | 3.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 253         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 10836       |\n",
      "|    total_timesteps      | 697508      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026165728 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.371      |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | 0.00157     |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 271         |\n",
      "|    ep_rew_mean          | 1.31e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 10866       |\n",
      "|    total_timesteps      | 699556      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029135445 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.113      |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 857         |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=1691.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.00e+03    |\n",
      "|    mean_reward          | 1.69e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009431312 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0921     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | 0.00143     |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 1.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 342      |\n",
      "|    time_elapsed    | 11005    |\n",
      "|    total_timesteps | 701604   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 296         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 11033       |\n",
      "|    total_timesteps      | 703652      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008612704 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | 0.00673     |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 314         |\n",
      "|    ep_rew_mean          | 1.34e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 11061       |\n",
      "|    total_timesteps      | 705700      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008706347 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0702     |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 333        |\n",
      "|    ep_rew_mean          | 1.34e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 345        |\n",
      "|    time_elapsed         | 11090      |\n",
      "|    total_timesteps      | 707748     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07392301 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.307     |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 13200      |\n",
      "|    policy_gradient_loss | 0.00494    |\n",
      "|    value_loss           | 37.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 353        |\n",
      "|    ep_rew_mean          | 1.36e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 346        |\n",
      "|    time_elapsed         | 11118      |\n",
      "|    total_timesteps      | 709796     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01199911 |\n",
      "|    clip_fraction        | 0.0883     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.292     |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 13210      |\n",
      "|    policy_gradient_loss | 0.000214   |\n",
      "|    value_loss           | 715        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 372        |\n",
      "|    ep_rew_mean          | 1.37e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 347        |\n",
      "|    time_elapsed         | 11146      |\n",
      "|    total_timesteps      | 711844     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15946054 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.317     |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 13220      |\n",
      "|    policy_gradient_loss | -0.00725   |\n",
      "|    value_loss           | 20.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 390        |\n",
      "|    ep_rew_mean          | 1.37e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 348        |\n",
      "|    time_elapsed         | 11173      |\n",
      "|    total_timesteps      | 713892     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15917519 |\n",
      "|    clip_fraction        | 0.0538     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.111     |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 18.4       |\n",
      "|    n_updates            | 13230      |\n",
      "|    policy_gradient_loss | -0.00313   |\n",
      "|    value_loss           | 257        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 1.36e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 11201       |\n",
      "|    total_timesteps      | 715940      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009154724 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0217     |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 274         |\n",
      "|    n_updates            | 13240       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 372         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 420         |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 11229       |\n",
      "|    total_timesteps      | 717988      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018273072 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 7.3         |\n",
      "|    n_updates            | 13250       |\n",
      "|    policy_gradient_loss | 0.0038      |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 442        |\n",
      "|    ep_rew_mean          | 1.4e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 351        |\n",
      "|    time_elapsed         | 11258      |\n",
      "|    total_timesteps      | 720036     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09372248 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.207     |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 6.45       |\n",
      "|    n_updates            | 13260      |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    value_loss           | 14.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 461         |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 11285       |\n",
      "|    total_timesteps      | 722084      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013838438 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.319      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 481        |\n",
      "|    ep_rew_mean          | 1.43e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 353        |\n",
      "|    time_elapsed         | 11313      |\n",
      "|    total_timesteps      | 724132     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21254672 |\n",
      "|    clip_fraction        | 0.428      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.341     |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 14.2       |\n",
      "|    n_updates            | 13280      |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 29.2       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=1675.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.00e+03    |\n",
      "|    mean_reward          | 1.68e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 725000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004184903 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 4.66        |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.000122   |\n",
      "|    value_loss           | 9.67        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 481      |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 354      |\n",
      "|    time_elapsed    | 11452    |\n",
      "|    total_timesteps | 726180   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 517          |\n",
      "|    ep_rew_mean          | 1.46e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 11480        |\n",
      "|    total_timesteps      | 728228       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046769516 |\n",
      "|    clip_fraction        | 0.0856       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.331       |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 2.96e+03     |\n",
      "|    n_updates            | 13300        |\n",
      "|    policy_gradient_loss | 0.00458      |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 533       |\n",
      "|    ep_rew_mean          | 1.45e+03  |\n",
      "|    winrate              | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 63        |\n",
      "|    iterations           | 356       |\n",
      "|    time_elapsed         | 11510     |\n",
      "|    total_timesteps      | 730276    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1111079 |\n",
      "|    clip_fraction        | 0.249     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.55     |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 3e-05     |\n",
      "|    loss                 | 5.16      |\n",
      "|    n_updates            | 13310     |\n",
      "|    policy_gradient_loss | -0.00534  |\n",
      "|    value_loss           | 11.3      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 559        |\n",
      "|    ep_rew_mean          | 1.49e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 357        |\n",
      "|    time_elapsed         | 11538      |\n",
      "|    total_timesteps      | 732324     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01077597 |\n",
      "|    clip_fraction        | 0.0645     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.12      |\n",
      "|    explained_variance   | 0.899      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 358        |\n",
      "|    n_updates            | 13320      |\n",
      "|    policy_gradient_loss | 0.00291    |\n",
      "|    value_loss           | 1.82e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 583          |\n",
      "|    ep_rew_mean          | 1.53e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 358          |\n",
      "|    time_elapsed         | 11566        |\n",
      "|    total_timesteps      | 734372       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146963885 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.126       |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 65.1         |\n",
      "|    n_updates            | 13330        |\n",
      "|    policy_gradient_loss | 0.00353      |\n",
      "|    value_loss           | 476          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 594         |\n",
      "|    ep_rew_mean          | 1.56e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 11593       |\n",
      "|    total_timesteps      | 736420      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423908 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | 0.0019      |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 622         |\n",
      "|    ep_rew_mean          | 1.59e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 11621       |\n",
      "|    total_timesteps      | 738468      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012829063 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.102      |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 617        |\n",
      "|    ep_rew_mean          | 1.67e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 361        |\n",
      "|    time_elapsed         | 11648      |\n",
      "|    total_timesteps      | 740516     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19179022 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.23      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 137        |\n",
      "|    n_updates            | 13360      |\n",
      "|    policy_gradient_loss | -0.00642   |\n",
      "|    value_loss           | 137        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 623         |\n",
      "|    ep_rew_mean          | 1.67e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 11675       |\n",
      "|    total_timesteps      | 742564      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027940191 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.131      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | 0.000368    |\n",
      "|    value_loss           | 800         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 641         |\n",
      "|    ep_rew_mean          | 1.67e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 11702       |\n",
      "|    total_timesteps      | 744612      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016357567 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 3.57e+03    |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | 0.00387     |\n",
      "|    value_loss           | 5.86e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 657         |\n",
      "|    ep_rew_mean          | 1.71e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 11730       |\n",
      "|    total_timesteps      | 746660      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022530219 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.324      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 672         |\n",
      "|    ep_rew_mean          | 1.71e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 11756       |\n",
      "|    total_timesteps      | 748708      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019617945 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 791         |\n",
      "|    n_updates            | 13400       |\n",
      "|    policy_gradient_loss | 0.00124     |\n",
      "|    value_loss           | 890         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=1707.00 +/- 0.00\n",
      "Episode length: 2005.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.00e+03     |\n",
      "|    mean_reward          | 1.71e+03     |\n",
      "| rollout/                |              |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 750000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063795093 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.294       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 22.1         |\n",
      "|    n_updates            | 13410        |\n",
      "|    policy_gradient_loss | 0.00493      |\n",
      "|    value_loss           | 154          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 682      |\n",
      "|    ep_rew_mean     | 1.79e+03 |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 366      |\n",
      "|    time_elapsed    | 11889    |\n",
      "|    total_timesteps | 750756   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | 1.82e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 11917       |\n",
      "|    total_timesteps      | 752804      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012993168 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.128      |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 703        |\n",
      "|    ep_rew_mean          | 1.83e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 368        |\n",
      "|    time_elapsed         | 11944      |\n",
      "|    total_timesteps      | 754852     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01856918 |\n",
      "|    clip_fraction        | 0.0747     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.155     |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 600        |\n",
      "|    n_updates            | 13430      |\n",
      "|    policy_gradient_loss | 0.00467    |\n",
      "|    value_loss           | 4.24e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 703          |\n",
      "|    ep_rew_mean          | 1.83e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 369          |\n",
      "|    time_elapsed         | 11971        |\n",
      "|    total_timesteps      | 756900       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120611265 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 79.4         |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | 0.00408      |\n",
      "|    value_loss           | 458          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | 1.83e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 11998       |\n",
      "|    total_timesteps      | 758948      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045960046 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0511     |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.000395   |\n",
      "|    value_loss           | 87.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 721        |\n",
      "|    ep_rew_mean          | 1.84e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 12025      |\n",
      "|    total_timesteps      | 760996     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10703819 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.144     |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 83.7       |\n",
      "|    n_updates            | 13460      |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 87.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | 1.84e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 12052       |\n",
      "|    total_timesteps      | 763044      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011475401 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.073      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    value_loss           | 414         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 740         |\n",
      "|    ep_rew_mean          | 1.84e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 12079       |\n",
      "|    total_timesteps      | 765092      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013345967 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0322     |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    value_loss           | 591         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 758         |\n",
      "|    ep_rew_mean          | 1.85e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 12106       |\n",
      "|    total_timesteps      | 767140      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011955915 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.167      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | 0.00576     |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 763         |\n",
      "|    ep_rew_mean          | 1.88e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 12134       |\n",
      "|    total_timesteps      | 769188      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026990907 |\n",
      "|    clip_fraction        | 0.032       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0499     |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | 0.00614     |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 762         |\n",
      "|    ep_rew_mean          | 1.85e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 12160       |\n",
      "|    total_timesteps      | 771236      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020924535 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.133      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    value_loss           | 522         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 711        |\n",
      "|    ep_rew_mean          | 1.73e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 377        |\n",
      "|    time_elapsed         | 12188      |\n",
      "|    total_timesteps      | 773284     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08073488 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.499     |\n",
      "|    explained_variance   | 0.679      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.13e+03   |\n",
      "|    n_updates            | 13520      |\n",
      "|    policy_gradient_loss | 0.00275    |\n",
      "|    value_loss           | 3.03e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=1435.00 +/- 0.00\n",
      "Episode length: 170.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 170        |\n",
      "|    mean_reward          | 1.44e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 775000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08937945 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.116     |\n",
      "|    explained_variance   | 0.253      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 6.73e+03   |\n",
      "|    n_updates            | 13530      |\n",
      "|    policy_gradient_loss | 0.01       |\n",
      "|    value_loss           | 1.44e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 683      |\n",
      "|    ep_rew_mean     | 1.7e+03  |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 378      |\n",
      "|    time_elapsed    | 12224    |\n",
      "|    total_timesteps | 775332   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 559        |\n",
      "|    ep_rew_mean          | 1.7e+03    |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 12251      |\n",
      "|    total_timesteps      | 777380     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01991828 |\n",
      "|    clip_fraction        | 0.041      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0329    |\n",
      "|    explained_variance   | 0.48       |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.49e+03   |\n",
      "|    n_updates            | 13540      |\n",
      "|    policy_gradient_loss | 0.00274    |\n",
      "|    value_loss           | 2.95e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | 1.64e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 12278       |\n",
      "|    total_timesteps      | 779428      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018425614 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.071      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 433         |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | 1.61e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 381          |\n",
      "|    time_elapsed         | 12305        |\n",
      "|    total_timesteps      | 781476       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068767667 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0648      |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 3.81e+03     |\n",
      "|    n_updates            | 13560        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 4.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 398          |\n",
      "|    ep_rew_mean          | 1.58e+03     |\n",
      "|    winrate              | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 12332        |\n",
      "|    total_timesteps      | 783524       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013867972 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00196     |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 99.6         |\n",
      "|    n_updates            | 13570        |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    value_loss           | 1.16e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 358        |\n",
      "|    ep_rew_mean          | 1.52e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 383        |\n",
      "|    time_elapsed         | 12360      |\n",
      "|    total_timesteps      | 785572     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00946288 |\n",
      "|    clip_fraction        | 0.0421     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0645    |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 2.42e+03   |\n",
      "|    n_updates            | 13580      |\n",
      "|    policy_gradient_loss | 0.00229    |\n",
      "|    value_loss           | 3.02e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 12388       |\n",
      "|    total_timesteps      | 787620      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013105193 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0745     |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 854         |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | 2.69e-05    |\n",
      "|    value_loss           | 884         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | 1.48e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 12416       |\n",
      "|    total_timesteps      | 789668      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017562585 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.345      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.98e+03    |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | 0.000711    |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 302         |\n",
      "|    ep_rew_mean          | 1.46e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 12444       |\n",
      "|    total_timesteps      | 791716      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036395546 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.435      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 245         |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 12472       |\n",
      "|    total_timesteps      | 793764      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012793927 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.072      |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 13620       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 476         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 244        |\n",
      "|    ep_rew_mean          | 1.49e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 388        |\n",
      "|    time_elapsed         | 12499      |\n",
      "|    total_timesteps      | 795812     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01236955 |\n",
      "|    clip_fraction        | 0.0511     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0745    |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 80         |\n",
      "|    n_updates            | 13630      |\n",
      "|    policy_gradient_loss | -0.00353   |\n",
      "|    value_loss           | 419        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 256        |\n",
      "|    ep_rew_mean          | 1.55e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 12527      |\n",
      "|    total_timesteps      | 797860     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02384838 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.537     |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 396        |\n",
      "|    n_updates            | 13640      |\n",
      "|    policy_gradient_loss | 0.00411    |\n",
      "|    value_loss           | 819        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 255         |\n",
      "|    ep_rew_mean          | 1.54e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 12554       |\n",
      "|    total_timesteps      | 799908      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017247211 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.311      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    value_loss           | 825         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=1690.00 +/- 0.00\n",
      "Episode length: 208.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 208        |\n",
      "|    mean_reward          | 1.69e+03   |\n",
      "| rollout/                |            |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 800000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01573161 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.382     |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 183        |\n",
      "|    n_updates            | 13660      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 1.63e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 283      |\n",
      "|    ep_rew_mean     | 1.6e+03  |\n",
      "|    winrate         | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 391      |\n",
      "|    time_elapsed    | 12592    |\n",
      "|    total_timesteps | 801956   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 277         |\n",
      "|    ep_rew_mean          | 1.64e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 12620       |\n",
      "|    total_timesteps      | 804004      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038351744 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.117      |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 628         |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | 0.00115     |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 276        |\n",
      "|    ep_rew_mean          | 1.63e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 393        |\n",
      "|    time_elapsed         | 12647      |\n",
      "|    total_timesteps      | 806052     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01165978 |\n",
      "|    clip_fraction        | 0.0497     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0847    |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 334        |\n",
      "|    n_updates            | 13680      |\n",
      "|    policy_gradient_loss | -2.72e-05  |\n",
      "|    value_loss           | 1.24e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 294         |\n",
      "|    ep_rew_mean          | 1.64e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 12674       |\n",
      "|    total_timesteps      | 808100      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017650124 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.112      |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 2.83e+03    |\n",
      "|    n_updates            | 13690       |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 300        |\n",
      "|    ep_rew_mean          | 1.62e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 395        |\n",
      "|    time_elapsed         | 12701      |\n",
      "|    total_timesteps      | 810148     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16109028 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 94.3       |\n",
      "|    n_updates            | 13700      |\n",
      "|    policy_gradient_loss | -0.0351    |\n",
      "|    value_loss           | 244        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 298         |\n",
      "|    ep_rew_mean          | 1.6e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 12728       |\n",
      "|    total_timesteps      | 812196      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014673037 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.208      |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    value_loss           | 4.34e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 297        |\n",
      "|    ep_rew_mean          | 1.59e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 397        |\n",
      "|    time_elapsed         | 12756      |\n",
      "|    total_timesteps      | 814244     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02334427 |\n",
      "|    clip_fraction        | 0.0657     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.125     |\n",
      "|    explained_variance   | 0.901      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 1.65e+03   |\n",
      "|    n_updates            | 13720      |\n",
      "|    policy_gradient_loss | -0.00515   |\n",
      "|    value_loss           | 5.64e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 315        |\n",
      "|    ep_rew_mean          | 1.59e+03   |\n",
      "|    winrate              | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 398        |\n",
      "|    time_elapsed         | 12784      |\n",
      "|    total_timesteps      | 816292     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03732895 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.444     |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 3e-05      |\n",
      "|    loss                 | 3.55e+03   |\n",
      "|    n_updates            | 13730      |\n",
      "|    policy_gradient_loss | 0.0031     |\n",
      "|    value_loss           | 3.54e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 1.6e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 12811       |\n",
      "|    total_timesteps      | 818340      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060755715 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 868         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 1.61e+03    |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 12843       |\n",
      "|    total_timesteps      | 820388      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024691906 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | 0.00232     |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 1.6e+03     |\n",
      "|    winrate              | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 12873       |\n",
      "|    total_timesteps      | 822436      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011564983 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.23       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 3e-05       |\n",
      "|    loss                 | 59          |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | 0.00203     |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp_algo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlog_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    247\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 250\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[0;32m    176\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:163\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:54\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 54\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     59\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:95\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\gym\\wrappers\\frame_stack.py:115\u001b[0m, in \u001b[0;36mFrameStack.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m--> 115\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes\u001b[38;5;241m.\u001b[39mappend(observation)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(), reward, done, info\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\gym\\core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m--> 323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, done, info\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\stable_baselines3\\common\\atari_wrappers.py:173\u001b[0m, in \u001b[0;36mMaxAndSkipEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    171\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip):\n\u001b[1;32m--> 173\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_buffer[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001b[0m, in \u001b[0;36mJoypadSpace.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mTake a step using the given action.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# take the step and record the output\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\gym\\wrappers\\time_limit.py:18\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32me:\\10mociclo\\Applied\\RL_Sonic-TheHedgehog\\venv38\\lib\\site-packages\\nes_py\\nes_env.py:300\u001b[0m, in \u001b[0;36mNESEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrollers[\u001b[38;5;241m0\u001b[39m][:] \u001b[38;5;241m=\u001b[39m action\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# pass the action to the emulator as an unsigned byte\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# get the reward for this step\u001b[39;00m\n\u001b[0;32m    302\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reward())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(hp_algo[\"time_steps\"],\n",
    "            callback=[log_callback, checkpoint_callback, eval_callback],\n",
    "            reset_num_timesteps=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
